{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a47c3f738724c58ac6614ba23d13580": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7657ab36835845ce8b22cbd35474fb6a",
              "IPY_MODEL_9e34bdcfe11f402eb4e561ff486df97a",
              "IPY_MODEL_a69c063e088c46249e89f52b9e0413d2"
            ],
            "layout": "IPY_MODEL_72d701ab21ac4e0eb7d6d7826a368f07"
          }
        },
        "7657ab36835845ce8b22cbd35474fb6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a1a5adaafae4abca1c0143fa769e0c0",
            "placeholder": "​",
            "style": "IPY_MODEL_03a192a94c3949239763146a19c26f8d",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "9e34bdcfe11f402eb4e561ff486df97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7c626938c014883bb973091d6b4c006",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf769fe2da634053830967d7c60b8a80",
            "value": 548105171
          }
        },
        "a69c063e088c46249e89f52b9e0413d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9db0f58235b24de2aee70821617a4ffd",
            "placeholder": "​",
            "style": "IPY_MODEL_95de2ac140b740eb9f8c86241592acac",
            "value": " 548M/548M [00:06&lt;00:00, 45.4MB/s]"
          }
        },
        "72d701ab21ac4e0eb7d6d7826a368f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a1a5adaafae4abca1c0143fa769e0c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "03a192a94c3949239763146a19c26f8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7c626938c014883bb973091d6b4c006": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf769fe2da634053830967d7c60b8a80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9db0f58235b24de2aee70821617a4ffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95de2ac140b740eb9f8c86241592acac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22d750a4ae2d40d7a24f21e97b96cad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7fab217e0ba24727bfd98e722e3503f5",
              "IPY_MODEL_7cdf002f5c5549198c0bfa439a487f08",
              "IPY_MODEL_a8ee124674124901bdc0af7f78fa213d"
            ],
            "layout": "IPY_MODEL_8c64fa15fca74bf2a1fdd53904ea857f"
          }
        },
        "7fab217e0ba24727bfd98e722e3503f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22f3870463ac4c7fbaf3030c695f644b",
            "placeholder": "​",
            "style": "IPY_MODEL_00a3cfdf78f74f6c8a547ed8b9782122",
            "value": "Downloading (…)neration_config.json: 100%"
          }
        },
        "7cdf002f5c5549198c0bfa439a487f08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32382056d7ee40f2896fd0eebaec7479",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bae6965fd4af43ada1c90930b7509327",
            "value": 124
          }
        },
        "a8ee124674124901bdc0af7f78fa213d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1d20fee7bbc47cd98e11ba52ce2bcfb",
            "placeholder": "​",
            "style": "IPY_MODEL_88d963ee76034f039eda9ff4e6337f56",
            "value": " 124/124 [00:00&lt;00:00, 7.90kB/s]"
          }
        },
        "8c64fa15fca74bf2a1fdd53904ea857f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f3870463ac4c7fbaf3030c695f644b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00a3cfdf78f74f6c8a547ed8b9782122": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32382056d7ee40f2896fd0eebaec7479": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bae6965fd4af43ada1c90930b7509327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1d20fee7bbc47cd98e11ba52ce2bcfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d963ee76034f039eda9ff4e6337f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0444ca45c00d4fe69d51629d1c885ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e31ab33799c42dc97229c223670a837",
              "IPY_MODEL_9639efb8fe9b496d8c69c6818117789b",
              "IPY_MODEL_8dcf6cb69fc947f6b82445ba46987f92"
            ],
            "layout": "IPY_MODEL_b041eb99aed84ddbb125880280f59701"
          }
        },
        "6e31ab33799c42dc97229c223670a837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04718e64dbce4354b1fd692ec8f6affd",
            "placeholder": "​",
            "style": "IPY_MODEL_79ac3d1e02e2489189042c0bd960983b",
            "value": "Map: 100%"
          }
        },
        "9639efb8fe9b496d8c69c6818117789b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2014ca0852a4fb585e3647a2aa12da7",
            "max": 320,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aa9225c0927547658110b454e06c5cb8",
            "value": 320
          }
        },
        "8dcf6cb69fc947f6b82445ba46987f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecf4fef9dd3342daae42088721507229",
            "placeholder": "​",
            "style": "IPY_MODEL_a039bf372e474a0a86ba288f0752dd79",
            "value": " 320/320 [00:00&lt;00:00, 1814.54 examples/s]"
          }
        },
        "b041eb99aed84ddbb125880280f59701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04718e64dbce4354b1fd692ec8f6affd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79ac3d1e02e2489189042c0bd960983b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2014ca0852a4fb585e3647a2aa12da7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa9225c0927547658110b454e06c5cb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ecf4fef9dd3342daae42088721507229": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a039bf372e474a0a86ba288f0752dd79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3ca1caa35d744e0abf54300c5187436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2f156aa0d49d42d9969d7933439e1e35",
              "IPY_MODEL_f8ea222e83f84cf7a714a39916720dfe",
              "IPY_MODEL_752e424d358d4a47a66b63d2fb89772d"
            ],
            "layout": "IPY_MODEL_3727a247ea5649aba2dc39f509f363ab"
          }
        },
        "2f156aa0d49d42d9969d7933439e1e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fccd62c72b184ee6bd0138aced3a145c",
            "placeholder": "​",
            "style": "IPY_MODEL_61042a5d341b486d8411d3f5600b9e32",
            "value": "Map: 100%"
          }
        },
        "f8ea222e83f84cf7a714a39916720dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d48608c7a8549008708e273de49a5c8",
            "max": 80,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fffebd14249b4ae18ef2f2481aedba87",
            "value": 80
          }
        },
        "752e424d358d4a47a66b63d2fb89772d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eba9c632f624416ea9354ddd95bf89cb",
            "placeholder": "​",
            "style": "IPY_MODEL_cc20d2866a284e3590f6436aff1f1bec",
            "value": " 80/80 [00:00&lt;00:00, 798.20 examples/s]"
          }
        },
        "3727a247ea5649aba2dc39f509f363ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fccd62c72b184ee6bd0138aced3a145c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61042a5d341b486d8411d3f5600b9e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3d48608c7a8549008708e273de49a5c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fffebd14249b4ae18ef2f2481aedba87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eba9c632f624416ea9354ddd95bf89cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc20d2866a284e3590f6436aff1f1bec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install xformers\n",
        "!pip install transformers[torch]\n",
        "!pip install datasets\n",
        "!pip install  torchtext\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wa8oVbHOWj89",
        "outputId": "8f0187f8-b047-41d4-b385-8f79739662aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting xformers\n",
            "  Downloading xformers-0.0.23-cp310-cp310-manylinux2014_x86_64.whl (213.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.23.5)\n",
            "Collecting torch==2.1.1 (from xformers)\n",
            "  Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1->xformers) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1->xformers) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1->xformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1->xformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1->xformers) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.1->xformers) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.1->xformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.1->xformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.1->xformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.1->xformers)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.1->xformers)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.1->xformers)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.1->xformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.1->xformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/124.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:30\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import transformers\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup, AutoModelForSequenceClassification, AutoModel, set_seed,  GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling, GPT2Model,  GPT2LMHeadModel, pipeline, Trainer, TrainingArguments,GPT2Config\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset as D1, DataLoader\n",
        "from tqdm import tqdm\n",
        "from datasets import Dataset, load_dataset\n",
        "from collections import defaultdict\n",
        "import time\n",
        "\n",
        "# Misc.\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "pXe28VowWneT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 6\n",
        "MAX_LEN = 30\n",
        "RANDOM_SEED = 16\n",
        "MODEL_NAME = \"gpt2\"\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "EPOCHS = 1\n",
        "token_size = 50257\n"
      ],
      "metadata": {
        "id": "peJnjWLsX6CN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def MODEL(n_layer):\n",
        "\n",
        "    model = GPT2LMHeadModel.from_pretrained('gpt2',n_layer=n_layer)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "s4dBz_cEesIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TLVLgsIoKrLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_set = 'bookcorpus'"
      ],
      "metadata": {
        "id": "5iugiOgurmf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"webtext.xlsx\")"
      ],
      "metadata": {
        "id": "t2D9lWK2HERc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "RF9RCTv7sXLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.head(400)"
      ],
      "metadata": {
        "id": "YVNgChVoKkrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "id": "c-W-Y4NCsbr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "max_ = float(\"-inf\")\n",
        "for i in df[\"text\"]:\n",
        "\n",
        "  max_ = max(len(i),max_)\n",
        "\n",
        "print(max_)\n",
        "\n",
        "CUTOFF_LEN = max_\n"
      ],
      "metadata": {
        "id": "01zT8gnQPHVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(batch_size,CUTOFF_LEN,token_size)\n",
        "\n",
        "def give_input_shape(a):\n",
        "\n",
        "    c1 = nn.Conv1d(CUTOFF_LEN, 32, 3, stride=2)\n",
        "    c2 = nn.Conv1d(32, 32, 3, stride=2)\n",
        "    p1 = nn.MaxPool2d(3, stride=2)\n",
        "    f = nn.Flatten()\n",
        "\n",
        "    a = c1(a)\n",
        "    a = c2(a)\n",
        "    a = p1(a)\n",
        "    a = f(a)\n",
        "\n",
        "    return a.shape[1]\n",
        "\n",
        "input_dim = give_input_shape(a)"
      ],
      "metadata": {
        "id": "0e0E3DXrQds0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim"
      ],
      "metadata": {
        "id": "hnlURgHGRZDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Discriminator():\n",
        "\n",
        "    D = nn.Sequential(\n",
        "    nn.Conv1d(CUTOFF_LEN, 32, 3, stride=2),\n",
        "    nn.Conv1d(32, 32, 3, stride=2),\n",
        "    nn.MaxPool2d(3, stride=2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(input_dim, 256),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(256, 1),\n",
        "    nn.Sigmoid())\n",
        "\n",
        "    return D"
      ],
      "metadata": {
        "id": "Bu1lK9AtQ6t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train,val = train_test_split(df,random_state = 42,test_size=0.2)"
      ],
      "metadata": {
        "id": "YxwvPXbeXlWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qd2goVHQYLKy",
        "outputId": "513b6f95-afdf-4d84-cc23-20b2506d0ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "320"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU6IXtM3sTJj",
        "outputId": "39136096-ebe3-420a-cca7-fb4dd6d20b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "aVefGb_wHxiE",
        "outputId": "80fbfd3c-cf5f-45c4-bddb-16b5242f430f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                               text\n",
              "0           0  usually , he would be tearing around the livin...\n",
              "1           1  but just one look at a minion sent him practic...\n",
              "2           2  that had been megan 's plan when she got him d...\n",
              "3           3  he 'd seen the movie almost by mistake , consi...\n",
              "4           4  she liked to think being surrounded by adults ...\n",
              "5           5               `` are n't you being a good boy ? ''\n",
              "6           6                                         she said .\n",
              "7           7                    mason barely acknowledged her .\n",
              "8           8  instead , his baby blues remained focused on t...\n",
              "9           9  since the movie was almost over , megan knew s..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-299347c7-d02c-4a6a-af6b-487844a48b40\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>usually , he would be tearing around the livin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>but just one look at a minion sent him practic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>that had been megan 's plan when she got him d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>he 'd seen the movie almost by mistake , consi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>she liked to think being surrounded by adults ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>`` are n't you being a good boy ? ''</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>she said .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>mason barely acknowledged her .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>instead , his baby blues remained focused on t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>since the movie was almost over , megan knew s...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-299347c7-d02c-4a6a-af6b-487844a48b40')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-299347c7-d02c-4a6a-af6b-487844a48b40 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-299347c7-d02c-4a6a-af6b-487844a48b40');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6c18f7ba-1f33-4d09-b3f7-b2ac45a134ff\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6c18f7ba-1f33-4d09-b3f7-b2ac45a134ff')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6c18f7ba-1f33-4d09-b3f7-b2ac45a134ff button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = Dataset.from_dict({\"text\" : list(train[\"text\"]) })\n",
        "data_val = Dataset.from_dict({\"text\" : list(val[\"text\"]) })"
      ],
      "metadata": {
        "id": "24MV6onEI-VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJWkVXV4Or7X",
        "outputId": "130ae03d-4b77-4508-a539-868aba78cafa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text'],\n",
              "    num_rows: 320\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "GgrzKQ2jKCce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(prompt):\n",
        "    # there's probably a way to do this with the tokenizer settings\n",
        "    # but again, gotta move fast\n",
        "    result = tokenizer(\n",
        "        prompt,\n",
        "        truncation=True,\n",
        "        max_length=CUTOFF_LEN,\n",
        "        padding='max_length',\n",
        "        return_tensors=None,\n",
        "    )\n",
        "\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def generate_and_tokenize_prompt(data_point):\n",
        "\n",
        "    tokenized_full_prompt = tokenize(data_point[\"text\"])\n",
        "\n",
        "    return tokenized_full_prompt\n",
        "\n",
        "def create_data_pt(data,batch_size = batch_size):\n",
        "\n",
        "    data.set_format(type='torch', columns=['text', 'input_ids', 'attention_mask', 'labels'])\n",
        "    data = torch.utils.data.DataLoader(data, batch_size=batch_size)\n",
        "    return data"
      ],
      "metadata": {
        "id": "Z89E78RnH0HC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_d = data_train.shuffle().map(generate_and_tokenize_prompt)\n",
        "val_d = data_val.shuffle().map(generate_and_tokenize_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "0444ca45c00d4fe69d51629d1c885ea5",
            "6e31ab33799c42dc97229c223670a837",
            "9639efb8fe9b496d8c69c6818117789b",
            "8dcf6cb69fc947f6b82445ba46987f92",
            "b041eb99aed84ddbb125880280f59701",
            "04718e64dbce4354b1fd692ec8f6affd",
            "79ac3d1e02e2489189042c0bd960983b",
            "c2014ca0852a4fb585e3647a2aa12da7",
            "aa9225c0927547658110b454e06c5cb8",
            "ecf4fef9dd3342daae42088721507229",
            "a039bf372e474a0a86ba288f0752dd79",
            "d3ca1caa35d744e0abf54300c5187436",
            "2f156aa0d49d42d9969d7933439e1e35",
            "f8ea222e83f84cf7a714a39916720dfe",
            "752e424d358d4a47a66b63d2fb89772d",
            "3727a247ea5649aba2dc39f509f363ab",
            "fccd62c72b184ee6bd0138aced3a145c",
            "61042a5d341b486d8411d3f5600b9e32",
            "3d48608c7a8549008708e273de49a5c8",
            "fffebd14249b4ae18ef2f2481aedba87",
            "eba9c632f624416ea9354ddd95bf89cb",
            "cc20d2866a284e3590f6436aff1f1bec"
          ]
        },
        "id": "BjNLfG-JItoU",
        "outputId": "0baa3bd9-cbda-486e-fb87-ffab93813282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/320 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0444ca45c00d4fe69d51629d1c885ea5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3ca1caa35d744e0abf54300c5187436"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_d2 =  create_data_pt(train_d)\n",
        "val_d2 =  create_data_pt(val_d)"
      ],
      "metadata": {
        "id": "Ox-eJj7XSDs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_d2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4_H481_SFkf",
        "outputId": "cb9cb1c9-4bfe-4351-b120-b97663a7a8dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7b97f60bead0>"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t_n_layer = 6\n",
        "s_n_layer = 3"
      ],
      "metadata": {
        "id": "wf4_OlPDlwlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M1 = MODEL(t_n_layer)\n",
        "M2 = MODEL(s_n_layer)\n",
        "D = Discriminator()\n",
        "\n",
        "\n",
        "optimizer = AdamW(M2.parameters(), lr=2e-5, correct_bias=False)\n",
        "D_optimizer = AdamW(D.parameters(), lr=2e-4, correct_bias=False)\n",
        "\n",
        "\n",
        "total_steps = len(train_d2) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=total_steps\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npr5USaBk9sh",
        "outputId": "64c3e354-3643-41c8-d72f-b9428f5079ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at gpt2 were not used when initializing GPT2LMHeadModel: ['h.6.attn.c_proj.weight', 'h.10.attn.c_proj.weight', 'h.6.ln_1.weight', 'h.9.ln_2.weight', 'h.7.mlp.c_proj.weight', 'h.11.mlp.c_proj.bias', 'h.7.attn.c_attn.weight', 'h.8.ln_1.weight', 'h.11.mlp.c_fc.bias', 'h.8.attn.c_attn.bias', 'h.11.ln_1.weight', 'h.8.mlp.c_fc.bias', 'h.9.ln_2.bias', 'h.8.attn.c_proj.weight', 'h.9.mlp.c_proj.weight', 'h.6.ln_2.bias', 'h.10.attn.c_attn.weight', 'h.6.mlp.c_fc.bias', 'h.6.ln_2.weight', 'h.11.ln_1.bias', 'h.10.mlp.c_proj.weight', 'h.11.ln_2.weight', 'h.7.mlp.c_fc.weight', 'h.11.mlp.c_fc.weight', 'h.9.ln_1.weight', 'h.10.ln_2.bias', 'h.7.attn.c_proj.bias', 'h.8.mlp.c_proj.bias', 'h.9.mlp.c_proj.bias', 'h.8.attn.c_attn.weight', 'h.8.attn.c_proj.bias', 'h.6.attn.bias', 'h.7.mlp.c_fc.bias', 'h.6.mlp.c_proj.bias', 'h.11.attn.bias', 'h.11.ln_2.bias', 'h.9.attn.c_attn.weight', 'h.7.mlp.c_proj.bias', 'h.10.ln_1.weight', 'h.10.ln_2.weight', 'h.7.ln_1.bias', 'h.8.ln_2.bias', 'h.10.mlp.c_fc.bias', 'h.8.mlp.c_fc.weight', 'h.10.ln_1.bias', 'h.10.attn.c_proj.bias', 'h.10.attn.c_attn.bias', 'h.10.mlp.c_proj.bias', 'h.7.ln_2.bias', 'h.7.ln_1.weight', 'h.6.attn.c_attn.weight', 'h.6.attn.c_attn.bias', 'h.9.mlp.c_fc.bias', 'h.6.mlp.c_proj.weight', 'h.6.ln_1.bias', 'h.7.attn.c_proj.weight', 'h.6.mlp.c_fc.weight', 'h.7.attn.bias', 'h.9.ln_1.bias', 'h.10.mlp.c_fc.weight', 'h.9.mlp.c_fc.weight', 'h.9.attn.c_proj.weight', 'h.7.ln_2.weight', 'h.8.ln_1.bias', 'h.10.attn.bias', 'h.9.attn.c_proj.bias', 'h.8.mlp.c_proj.weight', 'h.8.ln_2.weight', 'h.8.attn.bias', 'h.11.attn.c_proj.weight', 'h.11.attn.c_attn.weight', 'h.11.attn.c_proj.bias', 'h.9.attn.bias', 'h.11.mlp.c_proj.weight', 'h.11.attn.c_attn.bias', 'h.7.attn.c_attn.bias', 'h.6.attn.c_proj.bias', 'h.9.attn.c_attn.bias']\n",
            "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at gpt2 were not used when initializing GPT2LMHeadModel: ['h.6.attn.c_proj.weight', 'h.10.attn.c_proj.weight', 'h.3.ln_2.weight', 'h.6.ln_1.weight', 'h.9.ln_2.weight', 'h.7.mlp.c_proj.weight', 'h.11.mlp.c_proj.bias', 'h.7.attn.c_attn.weight', 'h.8.ln_1.weight', 'h.11.mlp.c_fc.bias', 'h.3.attn.c_attn.weight', 'h.8.attn.c_attn.bias', 'h.11.ln_1.weight', 'h.8.mlp.c_fc.bias', 'h.9.ln_2.bias', 'h.8.attn.c_proj.weight', 'h.9.mlp.c_proj.weight', 'h.6.ln_2.bias', 'h.10.attn.c_attn.weight', 'h.6.mlp.c_fc.bias', 'h.6.ln_2.weight', 'h.11.ln_1.bias', 'h.4.attn.c_attn.weight', 'h.4.attn.c_proj.weight', 'h.10.mlp.c_proj.weight', 'h.4.mlp.c_fc.bias', 'h.11.ln_2.weight', 'h.7.mlp.c_fc.weight', 'h.3.attn.c_proj.weight', 'h.5.attn.bias', 'h.5.attn.c_proj.weight', 'h.3.ln_2.bias', 'h.11.mlp.c_fc.weight', 'h.9.ln_1.weight', 'h.10.ln_2.bias', 'h.5.mlp.c_proj.bias', 'h.7.attn.c_proj.bias', 'h.8.mlp.c_proj.bias', 'h.9.mlp.c_proj.bias', 'h.8.attn.c_attn.weight', 'h.8.attn.c_proj.bias', 'h.6.attn.bias', 'h.7.mlp.c_fc.bias', 'h.6.mlp.c_proj.bias', 'h.11.attn.bias', 'h.11.ln_2.bias', 'h.4.attn.bias', 'h.9.attn.c_attn.weight', 'h.3.attn.c_attn.bias', 'h.3.attn.c_proj.bias', 'h.10.ln_2.weight', 'h.7.mlp.c_proj.bias', 'h.10.ln_1.weight', 'h.4.ln_2.bias', 'h.7.ln_1.bias', 'h.8.ln_2.bias', 'h.10.mlp.c_fc.bias', 'h.8.mlp.c_fc.weight', 'h.4.mlp.c_fc.weight', 'h.10.ln_1.bias', 'h.4.mlp.c_proj.bias', 'h.4.ln_1.bias', 'h.5.ln_1.bias', 'h.5.attn.c_attn.bias', 'h.10.attn.c_proj.bias', 'h.10.attn.c_attn.bias', 'h.10.mlp.c_proj.bias', 'h.3.attn.bias', 'h.7.ln_2.bias', 'h.7.ln_1.weight', 'h.3.ln_1.bias', 'h.6.attn.c_attn.weight', 'h.6.attn.c_attn.bias', 'h.9.mlp.c_fc.bias', 'h.6.mlp.c_proj.weight', 'h.6.ln_1.bias', 'h.3.mlp.c_fc.bias', 'h.7.attn.c_proj.weight', 'h.6.mlp.c_fc.weight', 'h.7.attn.bias', 'h.4.mlp.c_proj.weight', 'h.9.ln_1.bias', 'h.10.mlp.c_fc.weight', 'h.4.attn.c_proj.bias', 'h.5.mlp.c_fc.bias', 'h.3.ln_1.weight', 'h.4.ln_1.weight', 'h.9.mlp.c_fc.weight', 'h.4.ln_2.weight', 'h.9.attn.c_proj.weight', 'h.3.mlp.c_fc.weight', 'h.7.ln_2.weight', 'h.8.ln_1.bias', 'h.3.mlp.c_proj.weight', 'h.10.attn.bias', 'h.9.attn.c_proj.bias', 'h.8.mlp.c_proj.weight', 'h.8.ln_2.weight', 'h.8.attn.bias', 'h.5.mlp.c_fc.weight', 'h.11.attn.c_proj.weight', 'h.5.attn.c_attn.weight', 'h.5.mlp.c_proj.weight', 'h.11.attn.c_attn.weight', 'h.11.attn.c_proj.bias', 'h.9.attn.bias', 'h.11.mlp.c_proj.weight', 'h.11.attn.c_attn.bias', 'h.7.attn.c_attn.bias', 'h.6.attn.c_proj.bias', 'h.5.attn.c_proj.bias', 'h.9.attn.c_attn.bias', 'h.4.attn.c_attn.bias', 'h.5.ln_1.weight', 'h.5.ln_2.bias', 'h.3.mlp.c_proj.bias', 'h.5.ln_2.weight']\n",
            "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cross_loss = nn.CrossEntropyLoss()\n",
        "cosine_loss = nn.CosineEmbeddingLoss()\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "\n",
        "\n",
        "def discriminator_loss(output1,output2,D):\n",
        "\n",
        "\n",
        "    batch_size = len(output1)\n",
        "\n",
        "    real_labels = torch.ones(batch_size, 1).to(DEVICE)\n",
        "    fake_labels = torch.zeros(batch_size, 1).to(DEVICE)\n",
        "\n",
        "\n",
        "    outputs1 = D(output1)\n",
        "    d_loss_real = criterion(outputs1, real_labels)\n",
        "\n",
        "\n",
        "\n",
        "    outputs2 = D(output2)\n",
        "    d_loss_fake = criterion(outputs2, fake_labels)\n",
        "\n",
        "\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "\n",
        "    return d_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def student_gan_loss(student_logits,D):\n",
        "\n",
        "\n",
        "\n",
        "    labels = torch.ones(len(student_logits), 1).to(DEVICE)\n",
        "    g_loss = criterion(D(student_logits), labels)\n",
        "\n",
        "    return g_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def kd_loss(teacher_logits,student_logits,T=2):\n",
        "\n",
        "    soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
        "    soft_prob = nn.functional.softmax(student_logits / T, dim=-1)    #log_softmax\n",
        "\n",
        "    entropy_loss_val = cross_loss(soft_prob,soft_targets)\n",
        "\n",
        "    return entropy_loss_val\n",
        "\n",
        "def cosine_sim_loss(teacher_logits,student_logits,T= 2):\n",
        "\n",
        "\n",
        "    cosine_loss_val = 0\n",
        "    n = len(teacher_logits)\n",
        "\n",
        "    for i,j in zip(teacher_logits,student_logits):\n",
        "\n",
        "        soft_targets = nn.functional.softmax(i / T, dim=-1)\n",
        "        soft_prob = nn.functional.softmax(i / T, dim=-1)           #log_softmax\n",
        "\n",
        "        y = torch.ones(soft_prob.shape[0])\n",
        "\n",
        "        y = y.to(DEVICE)\n",
        "\n",
        "        cosine_loss_val += cosine_loss(soft_prob,soft_targets,y)\n",
        "\n",
        "    return cosine_loss_val /n\n",
        "\n",
        "\n",
        "\n",
        "def train_epoch(M1,M2,D,a = 0.25,b = 0.25 ,c = 0.25 ,d = 0.25):\n",
        "\n",
        "\n",
        "\n",
        "    M1 = M1.eval()  # Teacher set to evaluation mode\n",
        "    M2 = M2.train()\n",
        "    total_train_loss = 0\n",
        "\n",
        "\n",
        "    steps = 0\n",
        "\n",
        "\n",
        "    for batch in tqdm(train_d2):\n",
        "\n",
        "\n",
        "        b_input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        b_masks = batch[\"attention_mask\"].to(DEVICE)\n",
        "        b_labels = batch[\"labels\"].to(DEVICE)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # D_optimizer.zero_grad()\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            outputs1 = M1(b_input_ids,\n",
        "                          labels=b_labels,\n",
        "                          attention_mask = b_masks)\n",
        "\n",
        "\n",
        "        outputs2 = M2(b_input_ids,\n",
        "                          labels=b_labels,\n",
        "                          attention_mask = b_masks)\n",
        "\n",
        "\n",
        "        teacher_logits = outputs1[1]\n",
        "        student_logits = outputs2[1]\n",
        "\n",
        "\n",
        "\n",
        "        stu_loss = student_gan_loss(student_logits,D)\n",
        "\n",
        "\n",
        "        entropy_loss_val =  kd_loss(teacher_logits,student_logits)\n",
        "\n",
        "\n",
        "\n",
        "        auto_reg_loss = outputs2[0]\n",
        "\n",
        "\n",
        "        cosine_loss_val = cosine_sim_loss(teacher_logits,student_logits)\n",
        "\n",
        "\n",
        "\n",
        "        loss = (a*entropy_loss_val + b*auto_reg_loss + c*cosine_loss_val + d*stu_loss)\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        steps += 1\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "\n",
        "    return total_train_loss/steps\n",
        "\n",
        "\n",
        "\n",
        "def train_discriminator(M1,M2,D,T=2):\n",
        "\n",
        "\n",
        "    M1 = M1.eval()\n",
        "    M2 = M2.eval()\n",
        "    D = D.train()\n",
        "\n",
        "\n",
        "    steps = 0\n",
        "    total_dis_loss = 0\n",
        "\n",
        "    for batch in tqdm(train_d2):\n",
        "\n",
        "        b_input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        b_masks = batch[\"attention_mask\"].to(DEVICE)\n",
        "        b_labels = batch[\"labels\"].to(DEVICE)\n",
        "\n",
        "        D_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            outputs1 = M1(b_input_ids,\n",
        "                        labels=b_labels,\n",
        "                        attention_mask = b_masks)\n",
        "\n",
        "            outputs2 = M2(b_input_ids,\n",
        "                        labels=b_labels,\n",
        "                        attention_mask = b_masks)\n",
        "\n",
        "\n",
        "        teacher_logits = outputs1[1]\n",
        "        student_logits = outputs2[1]\n",
        "\n",
        "        teacher_logits = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
        "        student_logits = nn.functional.softmax(student_logits / T, dim=-1)\n",
        "\n",
        "\n",
        "        batch_size = len(student_logits)\n",
        "\n",
        "        real_labels = torch.ones(batch_size, 1).to(DEVICE)\n",
        "        fake_labels = torch.zeros(batch_size, 1).to(DEVICE)\n",
        "\n",
        "\n",
        "        o1 = D(teacher_logits)\n",
        "        d_loss_real = criterion(o1, real_labels)\n",
        "\n",
        "\n",
        "\n",
        "        o2 = D(student_logits)\n",
        "        d_loss_fake = criterion(o2, fake_labels)\n",
        "\n",
        "\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "\n",
        "        total_dis_loss += d_loss.item()\n",
        "\n",
        "        steps += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        d_loss.backward()\n",
        "        D_optimizer.step()\n",
        "\n",
        "    return total_dis_loss/steps\n",
        "\n",
        "\n",
        "def eval_model(M1,M2,D,a = 0.25,b = 0.25 ,c = 0.25 ,d = 0.25):\n",
        "\n",
        "\n",
        "\n",
        "    M1 = M1.eval()  # Teacher set to evaluation mode\n",
        "    M2 = M2.train()\n",
        "    total_val_loss = 0\n",
        "    steps = 0\n",
        "\n",
        "\n",
        "\n",
        "    for batch in tqdm(val_d2):\n",
        "\n",
        "\n",
        "        b_input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "        b_masks = batch[\"attention_mask\"].to(DEVICE)\n",
        "        b_labels = batch[\"labels\"].to(DEVICE)\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            outputs1 = M1(b_input_ids,\n",
        "                          labels=b_labels,\n",
        "                          attention_mask = b_masks)\n",
        "\n",
        "\n",
        "\n",
        "            outputs2 = M2(b_input_ids,\n",
        "                            labels=b_labels,\n",
        "                            attention_mask = b_masks)\n",
        "\n",
        "\n",
        "            teacher_logits = outputs1[1]\n",
        "            student_logits = outputs2[1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            stu_loss = student_gan_loss(student_logits,D)\n",
        "\n",
        "\n",
        "            entropy_loss_val =  kd_loss(teacher_logits,student_logits)\n",
        "\n",
        "            auto_reg_loss = outputs2[0]\n",
        "\n",
        "            cosine_loss_val = cosine_sim_loss(teacher_logits,student_logits)\n",
        "\n",
        "            loss = (a*entropy_loss_val + b*auto_reg_loss + c*cosine_loss_val + d*stu_loss)\n",
        "\n",
        "\n",
        "\n",
        "            total_val_loss  += loss.item()\n",
        "\n",
        "            steps += 1\n",
        "\n",
        "\n",
        "\n",
        "    return total_val_loss/steps\n",
        "\n",
        "def train(M1,M2,D,EPOCHS,verbose = True):\n",
        "\n",
        "    M1 = M1.to(DEVICE)\n",
        "    M2 = M2.to(DEVICE)\n",
        "    D = D.to(DEVICE)\n",
        "\n",
        "\n",
        "    if(verbose == True):\n",
        "\n",
        "        print()\n",
        "        print()\n",
        "        print()\n",
        "        print(M1)\n",
        "        print()\n",
        "        print(\"<->\"*100)\n",
        "        print()\n",
        "        print(M2)\n",
        "        print()\n",
        "        print(\"<->\"*100)\n",
        "        print()\n",
        "        print(D)\n",
        "        print()\n",
        "        print()\n",
        "        print()\n",
        "\n",
        "\n",
        "    # model = model.to(DEVICE)\n",
        "\n",
        "    tt = 0\n",
        "    d = defaultdict(list)\n",
        "\n",
        "\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "\n",
        "        print()\n",
        "        print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "        print('-' * 20)\n",
        "\n",
        "\n",
        "        s = time.time()\n",
        "        train_loss = train_epoch(M1,M2,D,)\n",
        "        e = time.time()\n",
        "\n",
        "        print(\"Time per epoch for training\", (e-s))\n",
        "\n",
        "\n",
        "        tt += (e-s)\n",
        "\n",
        "\n",
        "        val_loss = eval_model(M1,M2,D,)\n",
        "\n",
        "        dis_loss = train_discriminator(M1,M2,D,)\n",
        "\n",
        "        print()\n",
        "        print()\n",
        "        print(\"-\"*100)\n",
        "        print()\n",
        "        print(f' Train_loss {train_loss:.5f}  <->  Val_loss {val_loss:.5f} <-> Discriminator Loss {dis_loss: .5f}')\n",
        "        print()\n",
        "        print(\"-\"*100)\n",
        "        print()\n",
        "        print()\n",
        "\n",
        "\n",
        "        d[\"Train_loss\"].append(train_loss)\n",
        "        d[\"Val_loss\"].append(val_loss)\n",
        "        d[\"Discriminator_Loss\"].append(dis_loss)\n",
        "\n",
        "    print()\n",
        "    print()\n",
        "    print(\"*\"*100)\n",
        "    print()\n",
        "    print()\n",
        "    print()\n",
        "    print(\"Total time taken: \", tt)\n",
        "    print(\"Average time per epoch: \", tt/EPOCHS)\n",
        "    print()\n",
        "    print()\n",
        "    print()\n",
        "    print(\"*\"*100)\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "    return d\n"
      ],
      "metadata": {
        "id": "jgGtDRJLKHo2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "if(True):\n",
        "\n",
        "\n",
        "\n",
        "    # try:\n",
        "    print()\n",
        "    print(\"#\"*100)\n",
        "    print()\n",
        "    print()\n",
        "    print(\"#\"*100)\n",
        "    print()\n",
        "    print()\n",
        "    print(\"The Actual method\")\n",
        "    print(\"num_teacher_decoders: \", t_n_layer)\n",
        "    print(\"num_student_decoders: \", s_n_layer)\n",
        "    print()\n",
        "    print()\n",
        "\n",
        "    history1 = train(M1,M2,D,4)\n",
        "    d = pd.DataFrame(history1)\n",
        "\n",
        "    print()\n",
        "    print(\"*\"*100)\n",
        "    print()\n",
        "\n",
        "    print()\n",
        "    print(\"*\"*100)\n",
        "    print()\n",
        "\n",
        "    print()\n",
        "    print(d)\n",
        "    print()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    print(\"#\"*100)\n",
        "    print()\n",
        "    print()\n",
        "    print()\n",
        "    print(\"#\"*100)\n",
        "    print()\n",
        "\n",
        "    del M1\n",
        "    # del M2\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    # except Exception as e:\n",
        "\n",
        "        # print(e)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HBLWi5ayUDUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5be5bf8-d33f-4ce5-bf9b-42109b972e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "####################################################################################################\n",
            "\n",
            "\n",
            "####################################################################################################\n",
            "\n",
            "\n",
            "The Actual method\n",
            "num_teacher_decoders:  6\n",
            "num_student_decoders:  3\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-5): 6 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "<-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><->\n",
            "\n",
            "GPT2LMHeadModel(\n",
            "  (transformer): GPT2Model(\n",
            "    (wte): Embedding(50257, 768)\n",
            "    (wpe): Embedding(1024, 768)\n",
            "    (drop): Dropout(p=0.1, inplace=False)\n",
            "    (h): ModuleList(\n",
            "      (0-2): 3 x GPT2Block(\n",
            "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (attn): GPT2Attention(\n",
            "          (c_attn): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
            "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): GPT2MLP(\n",
            "          (c_fc): Conv1D()\n",
            "          (c_proj): Conv1D()\n",
            "          (act): NewGELUActivation()\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n",
            "\n",
            "<-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><-><->\n",
            "\n",
            "Sequential(\n",
            "  (0): Conv1d(272, 32, kernel_size=(3,), stride=(2,))\n",
            "  (1): Conv1d(32, 32, kernel_size=(3,), stride=(2,))\n",
            "  (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (3): Flatten(start_dim=1, end_dim=-1)\n",
            "  (4): Linear(in_features=94215, out_features=256, bias=True)\n",
            "  (5): LeakyReLU(negative_slope=0.2)\n",
            "  (6): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (7): Sigmoid()\n",
            ")\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Epoch 1/4\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 54/54 [00:24<00:00,  2.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time per epoch for training 24.445485591888428\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14/14 [00:03<00:00,  4.14it/s]\n",
            "100%|██████████| 54/54 [00:13<00:00,  4.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            " Train_loss 0.20622  <->  Val_loss 0.10783 <-> Discriminator Loss  1.59758\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Epoch 2/4\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 54/54 [00:24<00:00,  2.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time per epoch for training 24.915870666503906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14/14 [00:03<00:00,  4.38it/s]\n",
            "100%|██████████| 54/54 [00:12<00:00,  4.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            " Train_loss 0.10182  <->  Val_loss 0.10792 <-> Discriminator Loss  0.44758\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Epoch 3/4\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 54/54 [00:24<00:00,  2.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time per epoch for training 24.677441596984863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14/14 [00:03<00:00,  4.27it/s]\n",
            "100%|██████████| 54/54 [00:12<00:00,  4.22it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            " Train_loss 0.10144  <->  Val_loss 0.10768 <-> Discriminator Loss  0.04917\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "Epoch 4/4\n",
            "--------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 54/54 [00:24<00:00,  2.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time per epoch for training 24.848533868789673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14/14 [00:03<00:00,  4.28it/s]\n",
            "100%|██████████| 54/54 [00:12<00:00,  4.31it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            " Train_loss 0.10176  <->  Val_loss 0.10761 <-> Discriminator Loss  0.03422\n",
            "\n",
            "----------------------------------------------------------------------------------------------------\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "Total time taken:  98.88733172416687\n",
            "Average time per epoch:  24.721832931041718\n",
            "\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "\n",
            "   Train_loss  Val_loss  Discriminator_Loss\n",
            "0    0.206216  0.107827            1.597581\n",
            "1    0.101820  0.107920            0.447581\n",
            "2    0.101436  0.107682            0.049168\n",
            "3    0.101759  0.107606            0.034223\n",
            "\n",
            "####################################################################################################\n",
            "\n",
            "\n",
            "\n",
            "####################################################################################################\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del M2"
      ],
      "metadata": {
        "id": "Gh5EHKYpF0hE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del M1"
      ],
      "metadata": {
        "id": "wFMS5tC_i_DG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = MODEL(4)\n",
        "m = m.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F-9hyVbiJF5",
        "outputId": "e447daac-b5cd-40e8-e58d-89acd05e821d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at gpt2 were not used when initializing GPT2LMHeadModel: ['h.7.mlp.c_fc.bias', 'h.9.attn.c_attn.weight', 'h.6.attn.c_attn.weight', 'h.6.attn.bias', 'h.9.ln_2.bias', 'h.11.attn.c_proj.weight', 'h.9.attn.bias', 'h.4.mlp.c_proj.weight', 'h.5.attn.c_attn.weight', 'h.10.mlp.c_fc.weight', 'h.11.attn.c_attn.weight', 'h.6.attn.c_proj.weight', 'h.7.ln_2.bias', 'h.9.mlp.c_fc.bias', 'h.7.ln_1.weight', 'h.7.mlp.c_proj.weight', 'h.8.mlp.c_fc.bias', 'h.4.attn.c_attn.bias', 'h.5.ln_1.bias', 'h.5.mlp.c_fc.weight', 'h.9.mlp.c_fc.weight', 'h.10.mlp.c_fc.bias', 'h.10.attn.c_attn.weight', 'h.7.attn.c_proj.weight', 'h.8.attn.c_proj.bias', 'h.4.ln_2.weight', 'h.6.attn.c_attn.bias', 'h.4.mlp.c_fc.weight', 'h.6.ln_2.bias', 'h.7.ln_1.bias', 'h.7.ln_2.weight', 'h.9.attn.c_attn.bias', 'h.6.mlp.c_proj.weight', 'h.8.attn.c_attn.bias', 'h.9.attn.c_proj.weight', 'h.11.ln_1.bias', 'h.6.mlp.c_fc.bias', 'h.6.ln_1.bias', 'h.9.mlp.c_proj.bias', 'h.10.mlp.c_proj.weight', 'h.4.mlp.c_proj.bias', 'h.7.attn.c_proj.bias', 'h.7.attn.c_attn.weight', 'h.10.attn.c_proj.bias', 'h.7.attn.c_attn.bias', 'h.11.mlp.c_fc.weight', 'h.4.mlp.c_fc.bias', 'h.8.ln_1.bias', 'h.11.ln_2.weight', 'h.8.attn.bias', 'h.8.ln_2.bias', 'h.11.attn.bias', 'h.4.attn.c_proj.weight', 'h.4.ln_2.bias', 'h.10.attn.c_proj.weight', 'h.5.mlp.c_fc.bias', 'h.11.ln_1.weight', 'h.10.ln_2.weight', 'h.6.mlp.c_fc.weight', 'h.4.ln_1.bias', 'h.5.attn.c_proj.weight', 'h.5.attn.c_attn.bias', 'h.11.ln_2.bias', 'h.5.attn.c_proj.bias', 'h.8.ln_2.weight', 'h.5.ln_2.weight', 'h.7.attn.bias', 'h.10.mlp.c_proj.bias', 'h.6.attn.c_proj.bias', 'h.6.ln_2.weight', 'h.8.mlp.c_proj.bias', 'h.5.mlp.c_proj.bias', 'h.9.attn.c_proj.bias', 'h.10.attn.bias', 'h.4.ln_1.weight', 'h.5.mlp.c_proj.weight', 'h.4.attn.c_proj.bias', 'h.8.mlp.c_fc.weight', 'h.9.ln_2.weight', 'h.11.mlp.c_fc.bias', 'h.9.ln_1.bias', 'h.5.ln_1.weight', 'h.10.ln_2.bias', 'h.5.attn.bias', 'h.4.attn.c_attn.weight', 'h.7.mlp.c_proj.bias', 'h.7.mlp.c_fc.weight', 'h.9.mlp.c_proj.weight', 'h.9.ln_1.weight', 'h.6.ln_1.weight', 'h.11.attn.c_proj.bias', 'h.11.mlp.c_proj.bias', 'h.8.mlp.c_proj.weight', 'h.6.mlp.c_proj.bias', 'h.5.ln_2.bias', 'h.11.attn.c_attn.bias', 'h.8.attn.c_attn.weight', 'h.8.attn.c_proj.weight', 'h.10.ln_1.bias', 'h.11.mlp.c_proj.weight', 'h.4.attn.bias', 'h.10.ln_1.weight', 'h.8.ln_1.weight', 'h.10.attn.c_attn.bias']\n",
            "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D = Discriminator()"
      ],
      "metadata": {
        "id": "kajpJEy6PqAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = D.to(DEVICE)"
      ],
      "metadata": {
        "id": "YE5PlEoaPVsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D_optimizer = AdamW(D.parameters(), lr=2e-5, correct_bias=False)"
      ],
      "metadata": {
        "id": "vo3yh6MAIiwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "M1 = MODEL(4)\n",
        "M1 = M1.to(DEVICE)\n",
        "\n",
        "M2 = MODEL(4)\n",
        "M2 = M2.to(DEVICE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "2a47c3f738724c58ac6614ba23d13580",
            "7657ab36835845ce8b22cbd35474fb6a",
            "9e34bdcfe11f402eb4e561ff486df97a",
            "a69c063e088c46249e89f52b9e0413d2",
            "72d701ab21ac4e0eb7d6d7826a368f07",
            "9a1a5adaafae4abca1c0143fa769e0c0",
            "03a192a94c3949239763146a19c26f8d",
            "b7c626938c014883bb973091d6b4c006",
            "bf769fe2da634053830967d7c60b8a80",
            "9db0f58235b24de2aee70821617a4ffd",
            "95de2ac140b740eb9f8c86241592acac",
            "22d750a4ae2d40d7a24f21e97b96cad4",
            "7fab217e0ba24727bfd98e722e3503f5",
            "7cdf002f5c5549198c0bfa439a487f08",
            "a8ee124674124901bdc0af7f78fa213d",
            "8c64fa15fca74bf2a1fdd53904ea857f",
            "22f3870463ac4c7fbaf3030c695f644b",
            "00a3cfdf78f74f6c8a547ed8b9782122",
            "32382056d7ee40f2896fd0eebaec7479",
            "bae6965fd4af43ada1c90930b7509327",
            "b1d20fee7bbc47cd98e11ba52ce2bcfb",
            "88d963ee76034f039eda9ff4e6337f56"
          ]
        },
        "id": "lmhNj2hIFQbm",
        "outputId": "d09ed7bd-6ab8-4c05-c589-b91b946b796c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2a47c3f738724c58ac6614ba23d13580"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at gpt2 were not used when initializing GPT2LMHeadModel: ['h.8.ln_1.bias', 'h.11.attn.c_proj.weight', 'h.4.attn.c_attn.bias', 'h.8.ln_1.weight', 'h.8.mlp.c_fc.bias', 'h.8.mlp.c_proj.bias', 'h.9.attn.c_attn.bias', 'h.9.attn.c_proj.weight', 'h.11.attn.c_attn.weight', 'h.6.mlp.c_fc.bias', 'h.11.mlp.c_fc.bias', 'h.9.mlp.c_proj.weight', 'h.4.mlp.c_proj.bias', 'h.10.mlp.c_proj.weight', 'h.6.attn.c_proj.weight', 'h.7.attn.c_proj.bias', 'h.9.attn.bias', 'h.8.ln_2.bias', 'h.5.attn.c_proj.weight', 'h.6.mlp.c_fc.weight', 'h.5.ln_2.bias', 'h.11.mlp.c_fc.weight', 'h.5.mlp.c_fc.bias', 'h.4.attn.c_proj.weight', 'h.8.attn.c_proj.weight', 'h.6.ln_2.bias', 'h.7.attn.bias', 'h.11.attn.bias', 'h.7.ln_1.bias', 'h.7.attn.c_proj.weight', 'h.6.attn.c_proj.bias', 'h.4.ln_2.bias', 'h.5.mlp.c_proj.bias', 'h.5.ln_1.weight', 'h.9.ln_2.bias', 'h.9.mlp.c_fc.bias', 'h.11.ln_1.bias', 'h.7.ln_2.bias', 'h.7.attn.c_attn.weight', 'h.10.mlp.c_fc.bias', 'h.6.mlp.c_proj.bias', 'h.5.attn.c_attn.bias', 'h.4.ln_2.weight', 'h.7.mlp.c_proj.bias', 'h.10.mlp.c_fc.weight', 'h.11.ln_1.weight', 'h.10.attn.bias', 'h.9.ln_2.weight', 'h.9.attn.c_proj.bias', 'h.5.ln_1.bias', 'h.11.attn.c_proj.bias', 'h.11.attn.c_attn.bias', 'h.5.attn.bias', 'h.7.mlp.c_fc.bias', 'h.4.attn.c_attn.weight', 'h.8.attn.c_attn.bias', 'h.11.ln_2.bias', 'h.5.ln_2.weight', 'h.11.mlp.c_proj.weight', 'h.5.mlp.c_fc.weight', 'h.9.attn.c_attn.weight', 'h.4.ln_1.weight', 'h.4.attn.c_proj.bias', 'h.8.mlp.c_proj.weight', 'h.6.mlp.c_proj.weight', 'h.9.mlp.c_proj.bias', 'h.5.attn.c_proj.bias', 'h.8.attn.c_attn.weight', 'h.4.attn.bias', 'h.10.attn.c_proj.weight', 'h.9.mlp.c_fc.weight', 'h.7.mlp.c_proj.weight', 'h.6.ln_1.weight', 'h.5.mlp.c_proj.weight', 'h.10.ln_1.bias', 'h.8.mlp.c_fc.weight', 'h.4.mlp.c_fc.weight', 'h.8.attn.bias', 'h.7.mlp.c_fc.weight', 'h.11.ln_2.weight', 'h.9.ln_1.weight', 'h.6.attn.c_attn.weight', 'h.4.mlp.c_proj.weight', 'h.7.ln_2.weight', 'h.10.ln_2.bias', 'h.4.mlp.c_fc.bias', 'h.6.ln_2.weight', 'h.10.mlp.c_proj.bias', 'h.10.attn.c_attn.bias', 'h.6.attn.bias', 'h.8.attn.c_proj.bias', 'h.7.attn.c_attn.bias', 'h.10.attn.c_proj.bias', 'h.4.ln_1.bias', 'h.7.ln_1.weight', 'h.8.ln_2.weight', 'h.10.attn.c_attn.weight', 'h.9.ln_1.bias', 'h.10.ln_1.weight', 'h.6.ln_1.bias', 'h.6.attn.c_attn.bias', 'h.10.ln_2.weight', 'h.5.attn.c_attn.weight', 'h.11.mlp.c_proj.bias']\n",
            "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22d750a4ae2d40d7a24f21e97b96cad4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at gpt2 were not used when initializing GPT2LMHeadModel: ['h.8.ln_1.bias', 'h.11.attn.c_proj.weight', 'h.4.attn.c_attn.bias', 'h.8.ln_1.weight', 'h.8.mlp.c_fc.bias', 'h.8.mlp.c_proj.bias', 'h.9.attn.c_attn.bias', 'h.9.attn.c_proj.weight', 'h.11.attn.c_attn.weight', 'h.6.mlp.c_fc.bias', 'h.11.mlp.c_fc.bias', 'h.9.mlp.c_proj.weight', 'h.4.mlp.c_proj.bias', 'h.10.mlp.c_proj.weight', 'h.6.attn.c_proj.weight', 'h.7.attn.c_proj.bias', 'h.9.attn.bias', 'h.8.ln_2.bias', 'h.5.attn.c_proj.weight', 'h.6.mlp.c_fc.weight', 'h.5.ln_2.bias', 'h.11.mlp.c_fc.weight', 'h.5.mlp.c_fc.bias', 'h.4.attn.c_proj.weight', 'h.8.attn.c_proj.weight', 'h.6.ln_2.bias', 'h.7.attn.bias', 'h.11.attn.bias', 'h.7.ln_1.bias', 'h.7.attn.c_proj.weight', 'h.6.attn.c_proj.bias', 'h.4.ln_2.bias', 'h.5.mlp.c_proj.bias', 'h.5.ln_1.weight', 'h.9.ln_2.bias', 'h.9.mlp.c_fc.bias', 'h.11.ln_1.bias', 'h.7.ln_2.bias', 'h.7.attn.c_attn.weight', 'h.10.mlp.c_fc.bias', 'h.6.mlp.c_proj.bias', 'h.5.attn.c_attn.bias', 'h.4.ln_2.weight', 'h.7.mlp.c_proj.bias', 'h.10.mlp.c_fc.weight', 'h.11.ln_1.weight', 'h.10.attn.bias', 'h.9.ln_2.weight', 'h.9.attn.c_proj.bias', 'h.5.ln_1.bias', 'h.11.attn.c_proj.bias', 'h.11.attn.c_attn.bias', 'h.5.attn.bias', 'h.7.mlp.c_fc.bias', 'h.4.attn.c_attn.weight', 'h.8.attn.c_attn.bias', 'h.11.ln_2.bias', 'h.5.ln_2.weight', 'h.11.mlp.c_proj.weight', 'h.5.mlp.c_fc.weight', 'h.9.attn.c_attn.weight', 'h.4.ln_1.weight', 'h.4.attn.c_proj.bias', 'h.8.mlp.c_proj.weight', 'h.6.mlp.c_proj.weight', 'h.9.mlp.c_proj.bias', 'h.5.attn.c_proj.bias', 'h.8.attn.c_attn.weight', 'h.4.attn.bias', 'h.10.attn.c_proj.weight', 'h.9.mlp.c_fc.weight', 'h.7.mlp.c_proj.weight', 'h.6.ln_1.weight', 'h.5.mlp.c_proj.weight', 'h.10.ln_1.bias', 'h.8.mlp.c_fc.weight', 'h.4.mlp.c_fc.weight', 'h.8.attn.bias', 'h.7.mlp.c_fc.weight', 'h.11.ln_2.weight', 'h.9.ln_1.weight', 'h.6.attn.c_attn.weight', 'h.4.mlp.c_proj.weight', 'h.7.ln_2.weight', 'h.10.ln_2.bias', 'h.4.mlp.c_fc.bias', 'h.6.ln_2.weight', 'h.10.mlp.c_proj.bias', 'h.10.attn.c_attn.bias', 'h.6.attn.bias', 'h.8.attn.c_proj.bias', 'h.7.attn.c_attn.bias', 'h.10.attn.c_proj.bias', 'h.4.ln_1.bias', 'h.7.ln_1.weight', 'h.8.ln_2.weight', 'h.10.attn.c_attn.weight', 'h.9.ln_1.bias', 'h.10.ln_1.weight', 'h.6.ln_1.bias', 'h.6.attn.c_attn.bias', 'h.10.ln_2.weight', 'h.5.attn.c_attn.weight', 'h.11.mlp.c_proj.bias']\n",
            "- This IS expected if you are initializing GPT2LMHeadModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2LMHeadModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = AdamW(M2.parameters(), lr=2e-5, correct_bias=False)"
      ],
      "metadata": {
        "id": "UnLZtfuAPxGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cross_loss = nn.CrossEntropyLoss()\n",
        "cosine_loss = nn.CosineEmbeddingLoss()\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def discriminator_loss(output1,output2,D):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#     batch_size = len(output1)\n",
        "\n",
        "#     real_labels = torch.ones(batch_size, 1).to(DEVICE)\n",
        "#     fake_labels = torch.zeros(batch_size, 1).to(DEVICE)\n",
        "\n",
        "\n",
        "#     outputs1 = D(output1)\n",
        "#     d_loss_real = criterion(outputs1, real_labels)\n",
        "\n",
        "\n",
        "\n",
        "#     outputs2 = D(output2)\n",
        "#     d_loss_fake = criterion(outputs2, fake_labels)\n",
        "\n",
        "\n",
        "#     d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "#     D_optimizer.zero_grad()\n",
        "#     dis_loss.backward(retain_graph=True)\n",
        "#     D_optimizer.step()\n",
        "\n",
        "\n",
        "#     return d_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def student_gan_loss(student_logits,D):\n",
        "\n",
        "    labels = torch.ones(batch_size, 1).to(DEVICE)\n",
        "    g_loss = criterion(D(student_logits), labels)\n",
        "\n",
        "    return g_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def kd_loss(teacher_logits,student_logits,T=2):\n",
        "\n",
        "    soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
        "    soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n",
        "\n",
        "    entropy_loss_val = cross_loss(soft_prob,soft_targets)\n",
        "\n",
        "    return entropy_loss_val\n",
        "\n",
        "def cosine_sim_loss(teacher_logits,student_logits,T= 2):\n",
        "\n",
        "\n",
        "    cosine_loss_val = 0\n",
        "    n = len(teacher_logits)\n",
        "\n",
        "    for i,j in zip(teacher_logits,student_logits):\n",
        "\n",
        "        soft_targets = nn.functional.softmax(i / T, dim=-1)\n",
        "        soft_prob = nn.functional.log_softmax(i / T, dim=-1)\n",
        "\n",
        "        y = torch.ones(soft_prob.shape[0])\n",
        "\n",
        "        y = y.to(DEVICE)\n",
        "\n",
        "        cosine_loss_val += cosine_loss(soft_prob,soft_targets,y)\n",
        "\n",
        "    return cosine_loss_val /n\n",
        "\n",
        "\n",
        "steps = 0\n",
        "total_train_loss = 0\n",
        "\n",
        "\n",
        "\n",
        "for batch in tqdm(train_d2):\n",
        "\n",
        "\n",
        "\n",
        "    b_input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "    b_masks = batch[\"attention_mask\"].to(DEVICE)\n",
        "    b_labels = batch[\"labels\"].to(DEVICE)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        outputs1 = M1(b_input_ids,\n",
        "                    labels=b_labels,\n",
        "                    attention_mask = b_masks)\n",
        "\n",
        "\n",
        "    outputs2 = M2(b_input_ids,\n",
        "                    labels=b_labels,\n",
        "                    attention_mask = b_masks)\n",
        "\n",
        "\n",
        "    teacher_logits = outputs1[1]\n",
        "    student_logits = outputs2[1]\n",
        "\n",
        "\n",
        "\n",
        "    # soft_targets = nn.functional.softmax(teacher_logits / 2, dim=-1)\n",
        "    # soft_prob = nn.functional.log_softmax(student_logits / 2, dim=-1)\n",
        "\n",
        "\n",
        "    # dis_loss = discriminator_loss(teacher_logits,student_logits,D)\n",
        "\n",
        "\n",
        "    stu_loss = student_gan_loss(student_logits,D)\n",
        "\n",
        "\n",
        "    entropy_loss_val =  kd_loss(teacher_logits,student_logits)\n",
        "\n",
        "    auto_reg_loss = outputs2[0]\n",
        "\n",
        "    cosine_loss_val = cosine_sim_loss(teacher_logits,student_logits)\n",
        "\n",
        "    loss = (entropy_loss_val + auto_reg_loss + cosine_loss_val +stu_loss)/4\n",
        "\n",
        "\n",
        "    total_train_loss += loss.item()\n",
        "\n",
        "\n",
        "    steps += 1\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "\n",
        "    t1 = total_train_loss/steps\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if(steps == 3):\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "steps = 0\n",
        "total_dis_loss = 0\n",
        "\n",
        "for batch in tqdm(train_d2):\n",
        "\n",
        "    b_input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "    b_masks = batch[\"attention_mask\"].to(DEVICE)\n",
        "    b_labels = batch[\"labels\"].to(DEVICE)\n",
        "\n",
        "    D_optimizer.zero_grad()\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        outputs1 = M1(b_input_ids,\n",
        "                    labels=b_labels,\n",
        "                    attention_mask = b_masks)\n",
        "\n",
        "        outputs2 = M2(b_input_ids,\n",
        "                    labels=b_labels,\n",
        "                    attention_mask = b_masks)\n",
        "\n",
        "\n",
        "    teacher_logits = outputs1[1]\n",
        "    student_logits = outputs2[1]\n",
        "\n",
        "\n",
        "    batch_size = len(student_logits)\n",
        "\n",
        "    real_labels = torch.ones(batch_size, 1).to(DEVICE)\n",
        "    fake_labels = torch.zeros(batch_size, 1).to(DEVICE)\n",
        "\n",
        "\n",
        "    o1 = D(teacher_logits)\n",
        "    d_loss_real = criterion(o1, real_labels)\n",
        "\n",
        "\n",
        "\n",
        "    o2 = D(student_logits)\n",
        "    d_loss_fake = criterion(o2, fake_labels)\n",
        "\n",
        "\n",
        "    d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "\n",
        "    total_dis_loss += d_loss.item()\n",
        "\n",
        "    steps += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    d_loss.backward()\n",
        "    D_optimizer.step()\n",
        "\n",
        "    if(steps == 3):\n",
        "\n",
        "        break\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suXjRWkqPHQ3",
        "outputId": "e8af98c2-d548-4d40-8ec0-f284be91da9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▊       | 2/7 [00:00<00:02,  2.13it/s]\n",
            " 29%|██▊       | 2/7 [00:00<00:01,  3.44it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soft_targets = nn.functional.softmax(teacher_logits / 2, dim=-1)\n",
        "soft_prob = nn.functional.log_softmax(student_logits / 2, dim=-1)"
      ],
      "metadata": {
        "id": "hYAOxNQUXLOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soft_targets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx2k02x2HI-o",
        "outputId": "b9410ef6-e499-4371-827e-bfbe203137be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1.9224e-04, 2.0787e-04, 6.4163e-05,  ..., 9.1992e-06,\n",
              "          1.0541e-05, 2.1611e-04],\n",
              "         [2.0253e-04, 1.8524e-04, 1.4469e-06,  ..., 3.1037e-06,\n",
              "          7.9252e-06, 1.0457e-05],\n",
              "         [1.2642e-04, 5.6397e-05, 4.4338e-06,  ..., 2.9769e-08,\n",
              "          2.5920e-07, 4.2691e-06],\n",
              "         ...,\n",
              "         [3.0507e-05, 2.9509e-03, 4.6985e-04,  ..., 2.3781e-07,\n",
              "          4.8545e-08, 2.7130e-03],\n",
              "         [3.0058e-05, 2.9332e-03, 4.6921e-04,  ..., 2.3252e-07,\n",
              "          4.7802e-08, 2.7119e-03],\n",
              "         [3.0793e-05, 2.9737e-03, 4.7422e-04,  ..., 2.3772e-07,\n",
              "          4.8785e-08, 2.7517e-03]],\n",
              "\n",
              "        [[1.8541e-04, 1.9811e-04, 6.0498e-05,  ..., 9.3748e-06,\n",
              "          1.0803e-05, 2.1058e-04],\n",
              "         [3.2558e-04, 2.1044e-04, 5.1318e-05,  ..., 5.3115e-08,\n",
              "          3.7193e-07, 1.6476e-04],\n",
              "         [2.8958e-05, 1.2620e-05, 1.0072e-06,  ..., 2.6618e-06,\n",
              "          1.0340e-05, 3.2915e-06],\n",
              "         ...,\n",
              "         [1.9630e-05, 1.6429e-03, 3.4465e-04,  ..., 2.0159e-07,\n",
              "          9.0014e-08, 2.0756e-03],\n",
              "         [1.9223e-05, 1.6322e-03, 3.4644e-04,  ..., 1.9934e-07,\n",
              "          8.8995e-08, 2.0695e-03],\n",
              "         [1.9364e-05, 1.6523e-03, 3.4827e-04,  ..., 2.0167e-07,\n",
              "          9.0058e-08, 2.0779e-03]],\n",
              "\n",
              "        [[1.8933e-04, 1.9760e-04, 5.7825e-05,  ..., 9.1713e-06,\n",
              "          1.1079e-05, 2.0845e-04],\n",
              "         [6.4765e-05, 3.7279e-05, 7.0066e-06,  ..., 3.2877e-06,\n",
              "          9.9568e-05, 8.8022e-06],\n",
              "         [8.7191e-05, 9.7045e-05, 4.6522e-05,  ..., 1.9153e-06,\n",
              "          2.9438e-06, 3.4235e-05],\n",
              "         ...,\n",
              "         [1.5306e-05, 1.4152e-03, 4.4446e-04,  ..., 2.9645e-07,\n",
              "          1.2288e-07, 1.4781e-03],\n",
              "         [1.4775e-05, 1.4020e-03, 4.4321e-04,  ..., 2.9223e-07,\n",
              "          1.2028e-07, 1.4636e-03],\n",
              "         [1.4937e-05, 1.4190e-03, 4.4917e-04,  ..., 2.9594e-07,\n",
              "          1.2209e-07, 1.4641e-03]],\n",
              "\n",
              "        [[1.9358e-04, 2.0333e-04, 6.0006e-05,  ..., 8.9349e-06,\n",
              "          1.1003e-05, 2.0847e-04],\n",
              "         [1.3113e-05, 4.3794e-05, 4.8408e-06,  ..., 7.2746e-07,\n",
              "          1.9377e-06, 1.6621e-06],\n",
              "         [8.5681e-07, 1.1193e-05, 2.2529e-07,  ..., 3.1253e-08,\n",
              "          1.6103e-07, 4.9833e-07],\n",
              "         ...,\n",
              "         [3.0383e-05, 1.5719e-03, 4.3471e-04,  ..., 3.4023e-07,\n",
              "          2.1866e-07, 2.1096e-03],\n",
              "         [2.9316e-05, 1.5618e-03, 4.3168e-04,  ..., 3.3426e-07,\n",
              "          2.1446e-07, 2.0858e-03],\n",
              "         [2.9831e-05, 1.5813e-03, 4.3902e-04,  ..., 3.3953e-07,\n",
              "          2.1891e-07, 2.0875e-03]],\n",
              "\n",
              "        [[1.9358e-04, 2.0333e-04, 6.0006e-05,  ..., 8.9349e-06,\n",
              "          1.1003e-05, 2.0847e-04],\n",
              "         [7.9313e-05, 1.0152e-04, 3.4253e-05,  ..., 7.6329e-08,\n",
              "          2.2182e-06, 1.6076e-05],\n",
              "         [1.7618e-04, 3.8536e-04, 1.4306e-05,  ..., 1.1001e-06,\n",
              "          4.3529e-07, 1.6008e-05],\n",
              "         ...,\n",
              "         [3.5289e-05, 2.4384e-03, 3.9254e-04,  ..., 1.8786e-07,\n",
              "          8.5905e-08, 4.6166e-03],\n",
              "         [3.4295e-05, 2.4500e-03, 3.9101e-04,  ..., 1.8497e-07,\n",
              "          8.4075e-08, 4.5815e-03],\n",
              "         [3.5219e-05, 2.4863e-03, 3.9597e-04,  ..., 1.9061e-07,\n",
              "          8.6462e-08, 4.6168e-03]],\n",
              "\n",
              "        [[1.8691e-04, 1.9791e-04, 5.8989e-05,  ..., 9.1373e-06,\n",
              "          1.1254e-05, 2.0758e-04],\n",
              "         [3.0064e-05, 6.9042e-05, 1.4555e-05,  ..., 8.2497e-08,\n",
              "          1.7959e-06, 1.1452e-05],\n",
              "         [1.0702e-05, 8.0181e-04, 7.4495e-05,  ..., 7.9310e-08,\n",
              "          1.0532e-07, 1.8704e-06],\n",
              "         ...,\n",
              "         [3.6011e-05, 2.0834e-03, 3.6489e-04,  ..., 2.0384e-07,\n",
              "          1.2815e-07, 3.6181e-03],\n",
              "         [3.5283e-05, 2.0725e-03, 3.6518e-04,  ..., 2.0245e-07,\n",
              "          1.2624e-07, 3.6042e-03],\n",
              "         [3.5723e-05, 2.0897e-03, 3.6753e-04,  ..., 2.0690e-07,\n",
              "          1.2911e-07, 3.6211e-03]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soft_prob"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMxZKc9WHJS2",
        "outputId": "0b06ba6b-4b5b-4cd0-900d-cb663cdb31cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ -8.5407,  -8.4940,  -9.6640,  ..., -11.6055, -11.4552,  -8.3311],\n",
              "         [ -7.5650,  -8.8051, -12.9451,  ..., -13.6839, -11.9905,  -7.1827],\n",
              "         [ -6.9696,  -8.8572, -10.9832,  ..., -16.4497, -14.7009,  -8.2570],\n",
              "         ...,\n",
              "         [-10.1908, -10.5707, -11.3095,  ..., -19.6375, -19.3610,  -0.0764],\n",
              "         [-10.2026, -10.5620, -11.3012,  ..., -19.6264, -19.3502,  -0.0755],\n",
              "         [-10.1909, -10.5402, -11.2874,  ..., -19.6098, -19.3348,  -0.0767]],\n",
              "\n",
              "        [[ -8.5774,  -8.5349,  -9.7188,  ..., -11.5896, -11.4344,  -8.3653],\n",
              "         [ -6.8229,  -8.3580,  -9.8481,  ..., -16.6740, -14.4083,  -4.6330],\n",
              "         [ -9.1092, -11.2707, -13.6073,  ..., -13.2193, -12.4118,  -8.5256],\n",
              "         ...,\n",
              "         [-11.6779, -12.6136, -13.3653,  ..., -19.8713, -19.4888,  -0.0343],\n",
              "         [-11.7038, -12.6159, -13.3590,  ..., -19.8762, -19.5141,  -0.0335],\n",
              "         [-11.6990, -12.5992, -13.3472,  ..., -19.8447, -19.4882,  -0.0339]],\n",
              "\n",
              "        [[ -8.5595,  -8.5386,  -9.7662,  ..., -11.6103, -11.4090,  -8.3786],\n",
              "         [ -7.9897, -10.1846, -12.0633,  ..., -13.5085, -10.3239,  -7.0452],\n",
              "         [ -8.0811,  -9.2056, -10.1536,  ..., -14.3603, -13.5617,  -6.8990],\n",
              "         ...,\n",
              "         [-11.3866, -11.8987, -12.2232,  ..., -18.5127, -18.7179,  -0.0469],\n",
              "         [-11.3949, -11.8770, -12.2104,  ..., -18.4845, -18.6977,  -0.0468],\n",
              "         [-11.3922, -11.8686, -12.2005,  ..., -18.4679, -18.6833,  -0.0472]],\n",
              "\n",
              "        [[ -8.5344,  -8.5083,  -9.7291,  ..., -11.6361, -11.4186,  -8.3738],\n",
              "         [ -9.5105, -10.1936, -12.4388,  ..., -14.6789, -14.0557,  -8.2073],\n",
              "         [-12.0882, -11.3227, -15.1474,  ..., -17.5835, -16.7258, -10.2219],\n",
              "         ...,\n",
              "         [-11.0061, -12.0694, -12.5256,  ..., -18.4883, -18.2644,  -0.0845],\n",
              "         [-11.0367, -12.0787, -12.5398,  ..., -18.5001, -18.2932,  -0.0819],\n",
              "         [-11.0240, -12.0584, -12.5127,  ..., -18.4686, -18.2693,  -0.0831]],\n",
              "\n",
              "        [[ -8.5344,  -8.5083,  -9.7291,  ..., -11.6361, -11.4186,  -8.3738],\n",
              "         [ -7.6923,  -9.3193, -10.1104,  ..., -16.8157, -13.3436,  -5.5575],\n",
              "         [ -7.2411,  -7.4672, -10.5493,  ..., -14.1714, -14.8203,  -7.1358],\n",
              "         ...,\n",
              "         [-11.2593, -12.5467, -13.2837,  ..., -20.5433, -19.9040,  -0.0377],\n",
              "         [-11.2989, -12.5573, -13.2973,  ..., -20.5599, -19.9325,  -0.0364],\n",
              "         [-11.2802, -12.5440, -13.2755,  ..., -20.5175, -19.8928,  -0.0375]],\n",
              "\n",
              "        [[ -8.5693,  -8.5366,  -9.7471,  ..., -11.6143, -11.3970,  -8.3784],\n",
              "         [ -8.0605,  -9.2277, -10.3125,  ..., -16.2365, -13.2124,  -5.6316],\n",
              "         [ -9.1637,  -6.5551,  -8.7456,  ..., -16.1702, -15.6425,  -8.2438],\n",
              "         ...,\n",
              "         [-11.7127, -12.5997, -13.2107,  ..., -20.5896, -19.7968,  -0.0268],\n",
              "         [-11.7378, -12.6045, -13.2082,  ..., -20.5855, -19.8036,  -0.0263],\n",
              "         [-11.7340, -12.5874, -13.1936,  ..., -20.5469, -19.7629,  -0.0267]]],\n",
              "       device='cuda:0', grad_fn=<LogSoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in tqdm(train_d2):\n",
        "\n",
        "\n",
        "    b_input_ids = batch[\"input_ids\"].to(DEVICE)\n",
        "    b_masks = batch[\"attention_mask\"].to(DEVICE)\n",
        "    b_labels = batch[\"labels\"].to(DEVICE)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    # D_optimizer.zero_grad()\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        outputs1 = M1(b_input_ids,\n",
        "                        labels=b_labels,\n",
        "                        attention_mask = b_masks)\n",
        "\n",
        "\n",
        "    outputs2 = M2(b_input_ids,\n",
        "                        labels=b_labels,\n",
        "                        attention_mask = b_masks)\n",
        "\n",
        "\n",
        "    teacher_logits = outputs1[1]\n",
        "    student_logits = outputs2[1]\n",
        "\n",
        "\n",
        "\n",
        "    # soft_targets = nn.functional.softmax(teacher_logits / 2, dim=-1)\n",
        "    # soft_prob = nn.functional.log_softmax(student_logits / 2, dim=-1)\n",
        "\n",
        "\n",
        "    # dis_loss = discriminator_loss(teacher_logits,student_logits,D)\n",
        "\n",
        "    stu_loss = student_gan_loss(student_logits,D)\n",
        "\n",
        "\n",
        "    entropy_loss_val =  kd_loss(teacher_logits,student_logits)\n",
        "\n",
        "    auto_reg_loss = outputs2[0]\n",
        "\n",
        "    cosine_loss_val = cosine_sim_loss(teacher_logits,student_logits)\n",
        "\n",
        "    loss = (entropy_loss_val + auto_reg_loss + cosine_loss_val +stu_loss)/4\n",
        "\n",
        "\n",
        "    total_train_loss += loss.item()\n",
        "    # total_dis_loss += dis_loss.item()\n",
        "\n",
        "    steps += 1\n",
        "\n",
        "    loss.backward()\n",
        "    # dis_loss.backward()\n",
        "\n",
        "    # D_optimizer.step()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "I9qBewIDFEO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "w1GxWiEAE552"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3uwE5L6cAsp",
        "outputId": "3911c3d1-f422-4091-fb73-0778807a92eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.0383, device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entropy_loss_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9mxJX8-cC5q",
        "outputId": "4764ab16-2726-40ba-85ab-48dfdc901d01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0204, device='cuda:0', grad_fn=<DivBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_loss_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbhM8630cE9R",
        "outputId": "f335a056-d47f-422a-d50f-e55ee833815d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.0559, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auto_reg_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX-zrtmIcGSh",
        "outputId": "93116bb9-942a-438a-cde1-39ebb2231fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.6020, device='cuda:0', grad_fn=<NllLossBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stu_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-VfE_m7-cH2J",
        "outputId": "d531a016-f52c-42fd-f42e-bc32d054c10c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(outputs2[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eid1PbRDT_33",
        "outputId": "63f0b2e7-b6c8-4dcc-8caf-8a908f3083ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dU8y73BwSi8u",
        "outputId": "15ee2fb2-6c15-4e7c-ff33-24c5d45bc97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.5595, device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(teacher_logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh57qdCCRoou",
        "outputId": "67bff7f3-f811-4344-e55a-085e0a3c468f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entropy_loss_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKJEZ3KkFHrp",
        "outputId": "d7a2c704-3462-4824-8f1a-f20bb9e78949"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.7493, device='cuda:0', grad_fn=<DivBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZSuSUoRFq3z",
        "outputId": "3e64f1ab-e35d-4c76-d742-60629dda54ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([205, 50257])"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "entropy_loss_val"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nuc-095PFLzY",
        "outputId": "204cf94a-bd02-4654-f026-e45d71337298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.7493, device='cuda:0', grad_fn=<DivBackward1>)"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_logits.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnjkabSLDTYy",
        "outputId": "86697ee7-a89c-4a08-daad-18c4d4b00750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([205, 50257])"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs1[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G0PTwnrzESeX",
        "outputId": "d472eb28-d123-447b-d802-66b09f4e5d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 205, 50257])"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "D(outputs1[1][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "kbBl98SZEIPX",
        "outputId": "787b708c-06a8-447f-8aca-427a0f7db441"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-148-db66a31c8398>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    216\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    304\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 306\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    307\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soft_targets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbbeCMz2DViR",
        "outputId": "fbda21d1-4f0a-44cc-db09-0d394b8e53c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([205, 50257])"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uWTktUbP4TX",
        "outputId": "99b029c1-0c56-4210-a799-e8732d81069f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 205, 50257])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.input_shape = (205, 50257)\n",
        "\n",
        "        # Flatten the input\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # Define the dense layers\n",
        "        self.fc1 = nn.Linear(205 * 50257, 1024)\n",
        "        self.fc2 = nn.Linear(1024, 1024)\n",
        "        self.fc3 = nn.Linear(1024, 1024)\n",
        "        self.fc4 = nn.Linear(1024, 512)\n",
        "        # Define activation functions\n",
        "        self.relu = nn.LeakyReLU(0.2)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.sigmoid(x)  # Sigmoid activation for binary classification\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "tW6eQ077QeWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = Discriminator()"
      ],
      "metadata": {
        "id": "C-jkOW0wW1Mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "50257*205"
      ],
      "metadata": {
        "id": "Z2jBeWa1W3dr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "1000000000\n",
        "10302685"
      ],
      "metadata": {
        "id": "Bui9aTHiXN2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_size = 10302685\n",
        "hidden_size = 512"
      ],
      "metadata": {
        "id": "6QgBNx3QX3SS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = nn.Sequential(\n",
        "    nn.Linear(image_size, hidden_size),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(hidden_size, hidden_size),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(hidden_size, 1),\n",
        "    nn.Sigmoid())"
      ],
      "metadata": {
        "id": "O44EjbknXzrL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(224*224*3) / 10302685"
      ],
      "metadata": {
        "id": "qFJIPFJWX8Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = torch.randn(100, 1000)"
      ],
      "metadata": {
        "id": "RHDvVLUeYNCb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=100)\n",
        "reduced_data = pca.fit_transform(data)"
      ],
      "metadata": {
        "id": "M0rGMmkOeitH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XFcIe5jg6m3",
        "outputId": "2888dd3b-9806-4854-cc8e-2da008470f8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (conv_layer): Conv1d(3, 1, kernel_size=(3,), stride=(2,))\n",
              "  (output_layer): Sigmoid()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn((6, 205, 50257))"
      ],
      "metadata": {
        "id": "OsjJzrTFh_6g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs[1].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cEscFtriCsA",
        "outputId": "8caac28b-1c16-4855-c48a-989d2b96a168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 205, 50257])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFdqe8o0iFoX",
        "outputId": "dadfc17a-87ae-4fb8-b689-e2b562deba50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 3, 100])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = discriminator(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "CoboyO5ziQpj",
        "outputId": "4f0c2010-c053-4821-f61c-46b20a101f50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-29fbf4a7935e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-41445efbce78>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 310\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    304\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[0;32m--> 306\u001b[0;31m         return F.conv1d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    307\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [1, 3, 3], expected input[6, 205, 50257] to have 3 channels, but got 205 channels instead"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m = nn.Conv1d(205, 32, 3, stride=2)\n",
        "input = torch.randn(6, 205, 50257)\n",
        "output = m(input)"
      ],
      "metadata": {
        "id": "AsOfpgXdjzut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQBiWmhwj4EJ",
        "outputId": "87713bf2-458c-4cc5-bd5f-0cc281508d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 32, 25128])"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pool of square window of size=3, stride=2\n",
        "# m = nn.MaxPool2d(3, stride=2)\n",
        "# # pool of non-square window\n"
      ],
      "metadata": {
        "id": "FEkfePGAj5wt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwZrUP4omF9o",
        "outputId": "64cce482-70dd-4263-ec39-c668ac9fbec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([20, 16, 24, 31])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pool of square window of size=3, stride=2\n",
        "m = nn.MaxPool2d(3, stride=2)\n",
        "\n",
        "input = torch.randn(6, 205, 50257)\n",
        "output = m(input)"
      ],
      "metadata": {
        "id": "2AZr4C1-mHMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh-UVeTPm3E3",
        "outputId": "8813f9af-debb-497e-9029-e52dd1f4b433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 102, 25128])"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, in_channels=1, out_channels=32, kernel_size=3 ):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # Convolutional layer\n",
        "        self.conv1d = nn.Conv1d(in_channels=1, out_channels=32, kernel_size=3)\n",
        "\n",
        "        # Max pooling layer\n",
        "        self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64 * (input_length // 2 - 2), 128)  # Adjust input size accordingly\n",
        "        self.fc2 = nn.Linear(128, 1)  # Output layer for binary classification\n",
        "\n",
        "        # Activation functions\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply convolutional layer\n",
        "        x = self.conv1d(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        # Apply max pooling\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Flatten the output\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # Apply fully connected layers\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.sigmoid(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "miogGQgRm5nb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "6, 205, 50257"
      ],
      "metadata": {
        "id": "2FOmYUiIoz-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 6\n",
        "in_channels = 205\n",
        "input_length = 50257\n",
        "input_data = torch.randn(batch_size, in_channels, input_length)"
      ],
      "metadata": {
        "id": "953Spwe4oab4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator = Discriminator(in_channels=205)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "bq1NtuMOo7dx",
        "outputId": "b56633f4-85ce-49d0-f0f2-ac922c255cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-a40c464f00ca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m205\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Discriminator.__init__() got an unexpected keyword argument 'in_channels'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "input = torch.randn(6, 205, 50257)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8ApYJe9go9J5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = Discriminator()"
      ],
      "metadata": {
        "id": "z9vnmUhL-KhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d = D(input)"
      ],
      "metadata": {
        "id": "XOd-fBzI-Nhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yNRhs7o-Rd_",
        "outputId": "744ea726-f384-426e-e0ba-c3a4872ab2c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4796],\n",
              "        [0.4800],\n",
              "        [0.4738],\n",
              "        [0.4835],\n",
              "        [0.4920],\n",
              "        [0.4925]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cov = nn.Conv1d(205, 32, 3, stride=2)\n",
        "cov2 = nn.Conv1d(32, 32, 3, stride=2)\n",
        "pool = nn.MaxPool2d(3, stride=2)\n",
        "flat = nn.Flatten()"
      ],
      "metadata": {
        "id": "ls4VsN-QqCMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AXEMp3H1-NDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o1 = cov(input)"
      ],
      "metadata": {
        "id": "g4OCqwCtqEa0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vl1JbBlMqF-Z",
        "outputId": "b7303f35-27c3-4d18-a5e4-03a9a85b77a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 32, 25128])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "o1 = cov2(o1)"
      ],
      "metadata": {
        "id": "H76AkPu9q-2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "o1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4d6uxKZ7rB1o",
        "outputId": "8909fe38-e2e1-4110-b95d-50343244a81e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 32, 12563])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p = pool(o1)"
      ],
      "metadata": {
        "id": "j2psBMj5qHJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D8gugPfqY_p",
        "outputId": "faf5313d-9cfe-4a63-842f-34f5d8066e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 15, 6281])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = flat(p)"
      ],
      "metadata": {
        "id": "sd5Be3cqv8on"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LEZSA7bwF6e",
        "outputId": "fc73e15d-865d-4c43-9467-580aca6b6847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([6, 94215])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "205*50257"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz4tRH54qeQn",
        "outputId": "ff9db3ef-5005-416b-ddc2-822c7158460b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10302685"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1130670/10302685"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "em37g93Aqgpn",
        "outputId": "838a4cab-a027-46a4-af15-c6c19979601e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.10974517807736527"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self:\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        # 1D convolutional layer\n",
        "        self.conv1d = nn.Conv1d(in_channels=205, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2d = nn.Conv1d(in_channels=32 out_channels=32, kernel_size=3, stride=1, padding=1)\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.\n",
        "\n",
        "        # Max pooling layer\n",
        "        self.maxpool = nn.MaxPool1d(kernel_size=2)\n",
        "\n",
        "\n",
        "        self.fc1 = nn.Linear(64, 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.conv1d(x))\n",
        "        x = tor\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        # Flatten the output for fully connected layers\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Example usage:\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "JE5dcy7DqjEv",
        "outputId": "420fdd92-4146-4d79-b30f-2c6af90244d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-6e5a44ad34a4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# 1D convolutional layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-80-6e5a44ad34a4>\u001b[0m in \u001b[0;36mDiscriminator\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# 1D convolutional layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'input_size' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a sample input tensor with shape (batch_size, input_size, sequence_length)\n",
        "sample_input = torch.randn((1, 3, 128))  # Example input with 3 input channels and a sequence of length 128\n",
        "\n",
        "# Instantiate the Discriminator with the number of classes for binary classification (e.g., 1 for real, 0 for fake)\n",
        "num_classes = 1\n",
        "discriminator = Discriminator(input_size=3, num_classes=num_classes)\n",
        "\n",
        "# Forward pass to get the output\n",
        "output = discriminator(sample_input)\n",
        "\n",
        "print(\"Input shape:\", sample_input.shape)\n",
        "print(\"Output shape:\", output.shape) 94215"
      ],
      "metadata": {
        "id": "xBDpIsMwuxy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D = nn.Sequential(\n",
        "    nn.Conv1d(205, 32, 3, stride=2),\n",
        "    nn.Conv1d(32, 32, 3, stride=2),\n",
        "    nn.MaxPool2d(3, stride=2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(94215, 256),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(256, 1),\n",
        "    nn.Sigmoid())"
      ],
      "metadata": {
        "id": "KsdHCxp5wan2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    train_para = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    total_para = sum(p.numel() for p in model.parameters())\n",
        "\n",
        "    print(\"train para: \",train_para )\n",
        "    print(\"total para: \",total_para )\n",
        "    print(\"% fraction: \" , train_para / total_para)"
      ],
      "metadata": {
        "id": "iUl7KcR7wexu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_parameters(D)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHWuwCKXyH0I",
        "outputId": "ea51745d-81df-46ca-a890-c1c841057823"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train para:  24142369\n",
            "total para:  24142369\n",
            "% fraction:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "24142369/(1000000000/2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJti5cmhxbWM",
        "outputId": "1ac872c4-2317-4814-ad03-ae25a7e6b33b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.048284738"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "24140833/(1000000000/2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62tRl6-ayaYM",
        "outputId": "5d3f2d39-ffd1-48c8-93bf-95aa7f15c4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.048281666"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 256"
      ],
      "metadata": {
        "id": "ZKs2zLmxy8WP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "D2 = nn.Sequential(\n",
        "    nn.Linear(28*28, 256),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(hidden_size, hidden_size),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(hidden_size, 1),\n",
        "    nn.Sigmoid())"
      ],
      "metadata": {
        "id": "8aL9Z0ciypFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_parameters(D2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xnaQqF8y5Vt",
        "outputId": "041e0380-7929-49fc-8f24-dbb963f2d6d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train para:  267009\n",
            "total para:  267009\n",
            "% fraction:  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "267009/(1000000000/2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDeM42OgzCY8",
        "outputId": "196e0e08-5f7c-4377-c1b5-0ab6126c8e99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.000534018"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "bqqIsgBDzF48",
        "outputId": "82e15395-adfa-4d0c-8fe1-d682797369ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-128-2ff31c1eb101>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m205\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50257\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msingular_values_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    913\u001b[0m             )\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    916\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. PCA expected <= 2."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZiHJg0CBTNn",
        "outputId": "c5147f49-863b-42a2-d47d-eeeb8250a91e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4796],\n",
              "        [0.4800],\n",
              "        [0.4738],\n",
              "        [0.4835],\n",
              "        [0.4920],\n",
              "        [0.4925]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "one = torch.ones(6, 1)"
      ],
      "metadata": {
        "id": "It2E8vb1zWXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(6,205,50257)"
      ],
      "metadata": {
        "id": "42GHUM2SBZAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def give_input_shape(a):\n",
        "\n",
        "    c1 = nn.Conv1d(205, 32, 3, stride=2)\n",
        "    c2 = nn.Conv1d(32, 32, 3, stride=2)\n",
        "    p1 = nn.MaxPool2d(3, stride=2)\n",
        "    f = nn.Flatten()\n",
        "\n",
        "    a = c1(a)\n",
        "    a = c2(a)\n",
        "    a = p1(a)\n",
        "    a = f(a)\n",
        "\n",
        "    return a[1]\n"
      ],
      "metadata": {
        "id": "5yY5MLk5BZfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input.shape)\n",
        "\n",
        "a = c1(input)\n",
        "\n",
        "print(a.shape)\n",
        "\n",
        "a = c2(a)\n",
        "\n",
        "print(a.shape)\n",
        "\n",
        "a = p1(a)\n",
        "\n",
        "print(a.shape)\n",
        "\n",
        "a = f(a)\n",
        "\n",
        "print(a.shape)\n",
        "\n",
        "a = l1(a)\n",
        "\n",
        "print(a.shape)\n",
        "\n",
        "a = l2(a)\n",
        "\n",
        "print(a.shape)\n",
        "\n",
        "a = l2(a)\n",
        "\n",
        "print(a.shape)\n",
        "\n",
        "a = s(a)\n",
        "\n",
        "print(a.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhA8aFw8LMWL",
        "outputId": "3a4ddc4c-c477-4d9a-d2d4-d74a5bcc8663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([6, 32, 25128])\n",
            "torch.Size([6, 32, 12563])\n",
            "torch.Size([6, 15, 6281])\n",
            "torch.Size([6, 94215])\n",
            "torch.Size([6, 256])\n",
            "torch.Size([6, 256])\n",
            "torch.Size([6, 256])\n",
            "torch.Size([6, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Discriminator():\n",
        "\n",
        "    D = nn.Sequential(\n",
        "    nn.Conv1d(205, 32, 3, stride=2),\n",
        "    nn.Conv1d(32, 32, 3, stride=2),\n",
        "    nn.MaxPool2d(3, stride=2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(94215, 256),\n",
        "    nn.LeakyReLU(0.2),\n",
        "    nn.Linear(256, 1),\n",
        "    nn.Sigmoid())\n",
        "\n",
        "    return D"
      ],
      "metadata": {
        "id": "_m6r5IqSLgnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class DynamicCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(DynamicCNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv1d(in_channels=3, out_channels=16, kernel_size=3, stride=2)\n",
        "        self.conv2 = nn.Conv1d(in_channels=3, out_channels=16, kernel_size=3, stride=2)\n",
        "        self.pool1 = nn.MaxPool2d(3, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64, num_classes)\n",
        "\n",
        "        # Global average pooling\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.pool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.pool2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.pool3(x)\n",
        "\n",
        "        x = self.global_avg_pool(x)\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "KZm8q4PONHGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DynamicCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(DynamicCNN, self).__init__()\n",
        "\n",
        "        # Convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels=input_channels, out_channels=16, kernel_size=3, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Fully connected layers\n",
        "        self.fc1 = nn.Linear(64, num_classes)\n",
        "\n",
        "        # Global average pooling\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        print(x.shape)\n",
        "        x = self.relu1(x)\n",
        "        print(x.shape)\n",
        "        x = self.pool1(x)\n",
        "        print(x.shape)\n",
        "        x = self.conv2(x)\n",
        "        print(x.shape)\n",
        "        x = self.relu2(x)\n",
        "        print(x.shape)\n",
        "        x = self.pool2(x)\n",
        "        print(x.shape)\n",
        "        x = self.conv3(x)\n",
        "        print(x.shape)\n",
        "        x = self.relu3(x)\n",
        "        print(x.shape)\n",
        "        x = self.pool3(x)\n",
        "        print(x.shape)\n",
        "        x = self.global_avg_pool(x)\n",
        "        print(x.shape)\n",
        "        x = x.view(x.size(0), -1)  # Flatten\n",
        "        print(x.shape)\n",
        "        x = self.fc1(x)\n",
        "        print(x.shape)\n",
        "\n",
        "        return x\n",
        "\n",
        "# Example input shape (adjust according to your data)\n",
        "batch_size = 32\n",
        "input_channels = 128\n",
        "input_height = 128\n",
        "input_width = 128\n",
        "input_data = torch.randn(batch_size, input_channels, input_height, input_width)\n",
        "\n",
        "# Create an instance of the DynamicCNN model\n",
        "num_classes = 10  # Number of classes for classification\n",
        "model = DynamicCNN(num_classes)\n",
        "\n",
        "# Forward pass through the model\n",
        "output = model(input_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC8k6oFlNx46",
        "outputId": "3b2ac211-d7a8-45e6-f15d-e84900201a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 16, 128, 128])\n",
            "torch.Size([32, 16, 128, 128])\n",
            "torch.Size([32, 16, 64, 64])\n",
            "torch.Size([32, 32, 64, 64])\n",
            "torch.Size([32, 32, 64, 64])\n",
            "torch.Size([32, 32, 32, 32])\n",
            "torch.Size([32, 64, 32, 32])\n",
            "torch.Size([32, 64, 32, 32])\n",
            "torch.Size([32, 64, 16, 16])\n",
            "torch.Size([32, 64, 1, 1])\n",
            "torch.Size([32, 64])\n",
            "torch.Size([32, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GeX6Enq7N0By",
        "outputId": "d9e2f9bf-248a-42cc-e37a-f0df93b61dd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DynamicCNN(\n",
              "  (conv1): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu1): ReLU()\n",
              "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu2): ReLU()\n",
              "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu3): ReLU()\n",
              "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (fc1): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (global_avg_pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}