{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftwCkiW71m0M",
        "outputId": "368c35e6-e303-4a14-c812-139b98643383"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.3-py3-none-any.whl (974 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m974.0/974.0 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_core-0.2.5-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.7/314.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.1-py3-none-any.whl (23 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.75-py3-none-any.whl (124 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.9/124.9 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Installing collected packages: packaging, orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-2.4 langchain-0.2.3 langchain-core-0.2.5 langchain-text-splitters-0.2.1 langsmith-0.1.75 orjson-3.10.3 packaging-23.2\n",
            "Collecting openai\n",
            "  Downloading openai-1.33.0-py3-none-any.whl (325 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.5/325.5 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.6.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.4)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.33.0\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.23.2)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.2.5)\n",
            "Collecting sentence-transformers>=2.6.0 (from langchain-huggingface)\n",
            "  Downloading sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.1/227.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (0.19.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.10/dist-packages (from langchain-huggingface) (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.66 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (0.1.75)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (2.7.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.52->langchain-huggingface) (8.3.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (9.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain-huggingface) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.1.52->langchain-huggingface) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-huggingface) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain-huggingface) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.6.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers, langchain-huggingface\n",
            "Successfully installed langchain-huggingface-0.0.3 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 sentence-transformers-3.0.1\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.6.2)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.14.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.6.2)\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.31.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/309.4 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.3.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.23.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.5.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.31.0\n",
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.1-py3-none-manylinux_2_24_x86_64.whl (119.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.8/119.8 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.3.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->bitsandbytes) (12.5.40)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Installing collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.1\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.4-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core in /usr/local/lib/python3.10/dist-packages (0.2.5)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.6-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.3)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.75)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.3.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core) (2.7.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.4)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.0->langchain-community) (0.2.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.6 langchain-community-0.2.4 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.5)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.75)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.0->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain) (2.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install langchain-huggingface\n",
        "!pip install huggingface_hub\n",
        "!pip install transformers\n",
        "!pip install accelerate\n",
        "!pip install  bitsandbytes\n",
        "!pip install langchain-community langchain-core\n",
        "!pip install --upgrade langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrZpfVEi128h",
        "outputId": "6f1cfee7-771f-4d2c-9c82-9a9f262afcbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IylHwMxi16ue"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "from langchain.chains import SequentialChain\n",
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "from langchain_huggingface import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer,pipeline\n",
        "from langchain_huggingface import HuggingFaceEndpoint\n",
        "from langchain import HuggingFaceHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lpf2z17b3Q9K"
      },
      "outputs": [],
      "source": [
        "sec_key = \"\"\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=sec_key\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3Atl8744z_S"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/llm/data/Expanded_PROMISE.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDWDbboL7Xp1"
      },
      "outputs": [],
      "source": [
        "examples = []\n",
        "\n",
        "for i in range(len(df[\"RequirementText\"])):\n",
        "\n",
        "    obj = {\n",
        "        \"text\" : df[\"RequirementText\"][i],\n",
        "        \"class\" : \"Functional\" if df[\"Binary_Label\"][i] == 0 else \"Non Functional\"\n",
        "    }\n",
        "\n",
        "    examples.append(obj)\n",
        "\n",
        "\n",
        "random.shuffle(examples)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55Cl2fOv74rT",
        "outputId": "84e05f5e-2086-457d-bc56-c813a913fd18"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Text: If the leads score falls within the low average then it will be returned to the supplying vendor\n",
            "Functional\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompt_template = '''\n",
        "Text: {text}\n",
        "{class}\n",
        "'''\n",
        "\n",
        "example_prompt = PromptTemplate(input_variables=[\"text\",\"class\"],template = prompt_template)\n",
        "\n",
        "# print(example_prompt.format(**examples[0]))\n",
        "\n",
        "print(example_prompt.format(**examples[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxGGX0ykFCd1",
        "outputId": "cf9709ab-bb6e-48ee-a881-72e9fc43de8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'If the leads score falls within the low average then it will be returned to the supplying vendor',\n",
              " 'class': 'Functional'}"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i92KEnrJ-aAB",
        "outputId": "5582cd82-6f51-46d8-cfb5-629034df0ce2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'If the leads score falls within the low average then it will be returned to the supplying vendor',\n",
              " 'class': 'Functional'}"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "examples[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2UpvuTA75a6"
      },
      "outputs": [],
      "source": [
        "final_prompt = FewShotPromptTemplate(\n",
        "    examples=examples[:6],\n",
        "    example_prompt=example_prompt,\n",
        "    suffix= \"Text: {text}/n\",\n",
        "    input_variables=[\"text\"],\n",
        "    prefix= 'Classify the sentiment of the following text as \"Funtional\" or \"Non Funtional\"'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "laGPmfKg-fLU",
        "outputId": "28dc441d-02cb-4058-de68-654db508bf11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "FewShotPromptTemplate(input_variables=['text'], examples=[{'text': 'If the leads score falls within the low average then it will be returned to the supplying vendor', 'class': 'Functional'}, {'text': 'The system shall operate on Unix and Windows operating systems.', 'class': 'Non Functional'}, {'text': 'To prevent attacks the system should generate random word and ask the user to enter it correctly for multiple tryings.', 'class': 'Non Functional'}, {'text': 'The product shall be robust.The product shall have fault avoidance based on standards adoption.', 'class': 'Non Functional'}, {'text': 'The System shall meet all applicable accounting standards.  The final version of the System must successfully pass independent audit performed by a certified auditor.', 'class': 'Non Functional'}, {'text': 'The product shall comply with corporate User Interface Guidelines', 'class': 'Non Functional'}], example_prompt=PromptTemplate(input_variables=['class', 'text'], template='\\nText: {text}\\n{class}\\n'), suffix='Text: {text}/n', prefix='Classify the sentiment of the following text as \"Funtional\" or \"Non Funtional\"')"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "final_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bknaBPrs-fdK",
        "outputId": "4a721bc8-a8c5-4422-b76d-7862f5eaf3fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classify the sentiment of the following text as \"Funtional\" or \"Non Funtional\"\n",
            "\n",
            "\n",
            "Text: If the leads score falls within the low average then it will be returned to the supplying vendor\n",
            "Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall operate on Unix and Windows operating systems.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: To prevent attacks the system should generate random word and ask the user to enter it correctly for multiple tryings.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The product shall be robust.The product shall have fault avoidance based on standards adoption.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The System shall meet all applicable accounting standards.  The final version of the System must successfully pass independent audit performed by a certified auditor.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The product shall comply with corporate User Interface Guidelines\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The product shall be robust.The product shall have fault avoidance based on standards adoption./n\n"
          ]
        }
      ],
      "source": [
        "print(final_prompt.format(text =examples[3][\"text\"] ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3o40dAL_TtV"
      },
      "outputs": [],
      "source": [
        "llm = HuggingFaceHub(repo_id=\"declare-lab/flan-alpaca-large\", model_kwargs={\"temperature\":0, \"max_length\": 512})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJEFEkb7_wAF",
        "outputId": "9e6c8342-00b7-4cad-c629-cdd57946730b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HuggingFaceHub(client=<InferenceClient(model='declare-lab/flan-alpaca-large', timeout=None)>, repo_id='declare-lab/flan-alpaca-large', task='text2text-generation', model_kwargs={'temperature': 0, 'max_length': 512})"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXsV5YsQ_0Ws"
      },
      "source": [
        "# Test using Zero shot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsfCnCRL_wW6"
      },
      "outputs": [],
      "source": [
        "prompt_template = PromptTemplate(\n",
        "    template = \"What is a good name for a company that makes {product}\",\n",
        "    input_variables=[\"product\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8iAL6O8AJBi"
      },
      "outputs": [],
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "inOB_8rIAMnC"
      },
      "outputs": [],
      "source": [
        "a = chain.run(\"sports items\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HB_7gLfQATki",
        "outputId": "7407b14c-062f-4101-8a8e-ecca16647a4d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A good name for a company that makes sports items could be \"Sports Gear\".'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kNFCbV7VDZ0d",
        "outputId": "b508fbc7-4bb2-4469-e970-160a17250e8a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A good name for a company that makes sports items could be \"Sports Gear\".'"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(\"sports items\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpevCnUIBoXd",
        "outputId": "40e8f52d-a1fa-4203-85a4-fba52ec66e4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'product': 'sports items',\n",
              " 'text': 'A good name for a company that makes sports items could be \"Sports Gear\".'}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain(\"sports items\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kacW2M6fBoaG",
        "outputId": "8980d3aa-778e-4a86-8c57-5b0a61515885"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'product': 'sports items',\n",
              " 'text': 'A good name for a company that makes sports items could be \"Sports Gear\".'}"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke(\"sports items\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw2F3yp0EA62"
      },
      "source": [
        "# Zero shot on Promise dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fR-d-58hEF0d",
        "outputId": "5acffa5b-897f-4be7-9959-7c0469d9e41d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text: If the leads score falls within the low average then it will be returned to the supplying vendor'\n",
            "Classify the sentiment of the following text as 'Funtional' or 'Non Funtional'\n",
            "If the leads score falls within the low average then it will be returned to the supplying vendor'\n"
          ]
        }
      ],
      "source": [
        "text = \"If the leads score falls within the low average then it will be returned to the supplying vendor'\"\n",
        "prompt_template = '''Text: {text}'''\n",
        "\n",
        "example_prompt = PromptTemplate(input_variables=[\"text\"],template = prompt_template)\n",
        "\n",
        "print(example_prompt.format(text = text))\n",
        "\n",
        "\n",
        "text2 = \"Classify the sentiment of the following text as 'Funtional' or 'Non Funtional'\\nIf the leads score falls within the low average then it will be returned to the supplying vendor'\"\n",
        "prompt_template2 = '''{text}'''\n",
        "\n",
        "\n",
        "example_prompt2 = PromptTemplate(input_variables=[\"text\"],\n",
        "                                 template = prompt_template2,)\n",
        "\n",
        "\n",
        "print(example_prompt2.format(text = text2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vp4TSWEjEx9H",
        "outputId": "b3d993fc-5326-4222-8fe7-c9994cbe6d49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'If the leads score falls within the low average then it will be returned to the supplying vendor',\n",
              " 'class': 'Functional'}"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "examples[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "LMo33uwfBydk"
      },
      "outputs": [],
      "source": [
        "def preds(extraction_chain,n = 5 ,s = 1):\n",
        "\n",
        "    for i in range(n,n+5):\n",
        "        time.sleep(s)\n",
        "        print(\"*\"*100)\n",
        "        print()\n",
        "        print(\"Input Text\")\n",
        "        print(examples[i][\"text\"])\n",
        "        print()\n",
        "        print(\"Actual Class: \",examples[i][\"class\"] )\n",
        "        print()\n",
        "        print(\"Predicted: \", extraction_chain.run(text =examples[i][\"text\"] ))\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "hP83dBKZJNRT"
      },
      "outputs": [],
      "source": [
        "chain = LLMChain(llm=llm, prompt=example_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS83u7vxKksL",
        "outputId": "c512caa8-08e7-4f3d-a99b-093b9029e5a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LLMChain(prompt=PromptTemplate(input_variables=['text'], template='Text: {text}'), llm=HuggingFaceHub(client=<InferenceClient(model='declare-lab/flan-alpaca-large', timeout=None)>, repo_id='declare-lab/flan-alpaca-large', task='text2text-generation', model_kwargs={'temperature': 0, 'max_length': 512}))"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "muAOXxrCBygV",
        "outputId": "fce68f3c-0e0f-4a1d-997e-55f07ce896d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****************************************************************************************************\n",
            "\n",
            "Input Text\n",
            "The product shall comply with corporate User Interface Guidelines\n",
            "\n",
            "Actual Class:  Non Functional\n",
            "\n",
            "Predicted:  The product shall comply with the corporate User Interface Guidelines.\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "Input Text\n",
            "A clinical lab section shall include the clinical site name  the class  instructor  day and time of the lab.\n",
            "\n",
            "Actual Class:  Functional\n",
            "\n",
            "Predicted:  Clinical site name: University of California, Berkeley, California, USA, class instructor: Dr. John Smith, UC Berkeley, California, day and time of the lab: 8:00am - 5:00pm\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "Input Text\n",
            "The product shall protect the identity of the players. The product shall provide players no access to information that might reveal the identity of another player.\n",
            "\n",
            "Actual Class:  Non Functional\n",
            "\n",
            "Predicted:  The product shall provide players with no access to information that might reveal the identity of another player.\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "Input Text\n",
            "The estimator shall not apply recycled parts to the collision estimate if no available parts are returned.\n",
            "\n",
            "Actual Class:  Functional\n",
            "\n",
            "Predicted:  The estimator shall not apply recycled parts to the collision estimate if no available parts are returned.\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "Input Text\n",
            "The product will allow priviledged users to view meeting schedules in multiple reporting views.\n",
            "\n",
            "Actual Class:  Functional\n",
            "\n",
            "Predicted:  The product will allow priviledged users to view meeting schedules in multiple reporting views.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "preds(chain,n = 5 ,s = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFosttdULIZz"
      },
      "source": [
        "# FEW shot on Promise dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0OgxIvp6ByjU",
        "outputId": "f054a4b7-350f-4cd0-c7ca-c9c63fc177e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classify the sentiment of the following text as \"Funtional\" or \"Non Funtional\"\n",
            "\n",
            "\n",
            "Text: If the leads score falls within the low average then it will be returned to the supplying vendor\n",
            "Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall operate on Unix and Windows operating systems.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: To prevent attacks the system should generate random word and ask the user to enter it correctly for multiple tryings.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The product shall be robust.The product shall have fault avoidance based on standards adoption.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The System shall meet all applicable accounting standards.  The final version of the System must successfully pass independent audit performed by a certified auditor.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The product shall comply with corporate User Interface Guidelines\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The product shall be robust.The product shall have fault avoidance based on standards adoption./n\n"
          ]
        }
      ],
      "source": [
        "prompt_template = '''\n",
        "Text: {text}\n",
        "{class}\n",
        "'''\n",
        "\n",
        "example_prompt = PromptTemplate(input_variables=[\"text\",\"class\"],template = prompt_template)\n",
        "\n",
        "# print(example_prompt.format(**examples[0]))\n",
        "\n",
        "\n",
        "\n",
        "final_prompt = FewShotPromptTemplate(\n",
        "    examples=examples[:6],\n",
        "    example_prompt=example_prompt,\n",
        "    suffix= \"Text: {text}/n\",\n",
        "    input_variables=[\"text\"],\n",
        "    prefix= 'Classify the sentiment of the following text as \"Funtional\" or \"Non Funtional\"'\n",
        ")\n",
        "\n",
        "print(final_prompt.format(text =examples[3][\"text\"] ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "AGyBOemwBoiQ"
      },
      "outputs": [],
      "source": [
        "chain = LLMChain(llm = llm , prompt = final_prompt )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4gexuXuxPjOi",
        "outputId": "53bc45fd-0889-4790-ed75-35eb3b6f5951"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Functional'"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.run(text =examples[0][\"text\"] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "aQNILmdGPq7U",
        "outputId": "3f821caf-c752-4470-9942-40705166c4ea"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Functional'"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.predict(text =examples[0][\"text\"] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6b77tf5Ptai",
        "outputId": "afce498b-f855-4e2d-d63f-3345d785bcd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'Functional'}"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain(examples[0][\"text\"] )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "_07U_Rp0PeNZ"
      },
      "outputs": [],
      "source": [
        "def preds(extraction_chain,n = 5 ,s = 1):\n",
        "\n",
        "    for i in range(n,n+1):\n",
        "        time.sleep(s)\n",
        "        print(\"*\"*100)\n",
        "        print()\n",
        "        print(\"Input Text\")\n",
        "        print(examples[i][\"text\"])\n",
        "        print()\n",
        "        print(\"Actual Class: \",examples[i][\"class\"] )\n",
        "        print()\n",
        "        print(\"Predicted: \", extraction_chain.run(text = examples[i][\"text\"] )) #input is text\n",
        "        print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKtn0gp_Q5wz",
        "outputId": "716a7885-270f-4167-a014-a9cd6d10ce0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****************************************************************************************************\n",
            "\n",
            "Input Text\n",
            "The product shall comply with corporate User Interface Guidelines\n",
            "\n",
            "Actual Class:  Non Functional\n",
            "\n",
            "Predicted:   The product shall display error messages that are clear, concise, and easy to understand.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system must be able to process 1000 transactions per second.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The database schema shall include the following tables: Customers, Orders, and Order_Details.\n",
            "Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall be designed with a modular architecture, allowing for easy maintenance and upgrades.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall provide the ability for users to search for data using keywords.\n",
            "Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall be designed for scalability and high availability.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall support multiple users and allow for concurrent access to data.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall provide the ability to generate reports in CSV format.\n",
            "Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall be designed to meet the performance requirements of the business.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall support integration with third-party systems through APIs.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall support integration with third-party payment gateways for processing transactions.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall provide real-time alerts for critical events.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall provide an easy-to-use interface for administrators to manage users and permissions.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall provide an easy-to-use interface for users to place orders.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall provide an easy-to-use interface for users to view their order history.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall provide an easy-to-use interface for users to view their account information.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall provide an easy-to-use interface for users to cancel orders.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall provide an easy-to-use interface for users to modify their account information.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall provide an easy-to-use interface for users to view their invoices.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall provide an easy-to\n",
            "\n"
          ]
        }
      ],
      "source": [
        "preds(chain,n = 5 ,s = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QGK5zXuV4kd"
      },
      "source": [
        "# HuggingFaceEndpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYOerLIBWBZ7",
        "outputId": "b54b0c9f-939e-4b41-b211-e1ed9b0f4457"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:langchain_huggingface.llms.huggingface_endpoint:WARNING! max_length is not default parameter.\n",
            "                    max_length was transferred to model_kwargs.\n",
            "                    Please make sure that max_length is what you intended.\n",
            "WARNING:langchain_huggingface.llms.huggingface_endpoint:WARNING! token is not default parameter.\n",
            "                    token was transferred to model_kwargs.\n",
            "                    Please make sure that token is what you intended.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "#APi based\n",
        "\n",
        "repo_id=\"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "llm=HuggingFaceEndpoint(repo_id=repo_id,max_length=128,temperature=0.7,token=sec_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rZZPakKPaqcW",
        "outputId": "252bf251-65f8-4441-b888-3e662a3233d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HuggingFaceEndpoint(repo_id='mistralai/Mistral-7B-Instruct-v0.2', temperature=0.7, model_kwargs={'max_length': 128, 'token': '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'}, model='mistralai/Mistral-7B-Instruct-v0.2', client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.2', timeout=120)>, async_client=<InferenceClient(model='mistralai/Mistral-7B-Instruct-v0.2', timeout=120)>)"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "f6CIlysYWBik",
        "outputId": "af35b530-5b3e-4c02-80b2-88c5c5506346"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n\\nI am the artist and graphic designer, known as The Doodleman, specializing in hand-drawn illustrations and digital graphic design. I was born in the United States but currently reside in Tokyo, Japan.\\n\\nWhen did you start drawing?\\n\\nI started drawing at a very young age. My parents always encouraged my creativity and I was always drawing something. I didn't really start taking it seriously until college when I decided to major in Fine Arts and Graphic Design.\\n\\nWhat inspires you?\\n\\nI find inspiration in many things, but mostly from nature, music, and daily life. I also enjoy observing people and their interactions. I am always trying to find the beauty in the mundane.\\n\\nWhat materials do you prefer to use?\\n\\nI enjoy using a variety of materials, but my favorite medium is ink and watercolor. I find the unpredictability of watercolor and the control of ink to be a great balance. I also enjoy using digital tools such as Adobe Illustrator and Photoshop.\\n\\nWhat is your favorite drawing you have ever done?\\n\\nIt's difficult to choose a favorite drawing as each one holds a special place in my heart. But if I had to choose one, it would probably be a hand-drawn portrait of my grandmother. It was one of the first portraits I ever drew and it holds a lot of sentimental value to me.\\n\\nWhat advice would you give to aspiring artists?\\n\\nMy advice to aspiring artists would be to keep practicing and never give up. There will be challenges and setbacks, but keep pushing forward. Find inspiration in the world around you and don't be afraid to experiment with new techniques and mediums. And most importantly, have fun and enjoy the process!\\n\\nWhat are some of your favorite artists or influences?\\n\\nSome of my favorite artists include Vincent Van Gogh, Pablo Picasso, and Edward Hopper. I am also influenced by Japanese art, particularly ukiyo-e and manga. I enjoy the simplicity and elegance of traditional Japanese art, as well as the storytelling aspect of manga.\\n\\nWhat do you like to do when you're not drawing?\\n\\nWhen I'm not drawing, I enjoy traveling, hiking, and exploring new places. I also enjoy listening to music, playing the guitar, and trying new foods. And of course\""
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"Who are you?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "uqjaAqmtWBnt",
        "outputId": "a6deab6f-ba8d-41a9-9be0-59e5663805d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' and how does it work? Machine learning is a subset of artificial intelligence that involves training a computer system to learn and make decisions based on data, without being explicitly programmed. It uses algorithms and statistical models to identify patterns and make predictions or classifications. The machine learning model is trained on a large dataset, which allows it to learn the underlying relationships and make accurate predictions or decisions. Once trained, the model can be used to make predictions or decisions on new, unseen data. The process of machine learning can be divided into three main stages: data preparation, model selection and training, and prediction or decision-making. In data preparation, the data is cleaned, preprocessed, and transformed into a format that can be used by the machine learning algorithms. In model selection and training, the appropriate machine learning algorithm is chosen, and the model is trained on the prepared data. Finally, in prediction or decision-making, the model is used to make predictions or decisions based on new data. Machine learning is used in a wide range of applications, including image and speech recognition, natural language processing, fraud detection, and recommendation systems. It is a powerful tool for extracting insights and making predictions from large, complex datasets.'"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.predict(\"What is machine learning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "Qg2XpSB4Xzn1",
        "outputId": "1ab0c33b-c3ef-45e3-b595-555d2bc0441b"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'HuggingFaceEndpoint' object has no attribute 'run'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-85-f7f5c585ae5d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"What is machine learning\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'HuggingFaceEndpoint' object has no attribute 'run'"
          ]
        }
      ],
      "source": [
        "llm.run(\"What is machine learning\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1j1OzupXIpS",
        "outputId": "9aebd41f-6703-4937-94a0-3d5a60409698"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_variables=['question'] template=\"Question: {question}\\nAnswer: Let's think step by step.\"\n"
          ]
        }
      ],
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        "\n",
        "question=\"Who won the Cricket World Cup in the year 2011?\"\n",
        "template = \"\"\"Question: {question}\n",
        "Answer: Let's think step by step.\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "print(prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "payfKgJrXbMi",
        "outputId": "7dd84eff-cfa5-4a28-85c2-03ef635b049d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'question': 'Who won the Cricket World Cup in the year 2011?', 'text': \" The Cricket World Cup is a cricket tournament that takes place every four years. The tournament was held in 2011, so the team that won that year's tournament is the answer to this question. The winning team in 2011 was India. So, the answer is: India won the Cricket World Cup in the year 2011.\"}\n"
          ]
        }
      ],
      "source": [
        "llm_chain=LLMChain(llm=llm,prompt=prompt)\n",
        "print(llm_chain.invoke(question))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "4gA5X97aXdVS",
        "outputId": "e01b2050-25eb-4e47-e415-d78598df7abe"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Chain.invoke() missing 1 required positional argument: 'input'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-8b881f980ad8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: Chain.invoke() missing 1 required positional argument: 'input'"
          ]
        }
      ],
      "source": [
        "print(llm_chain.invoke(question = question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9w3fklNYYtx",
        "outputId": "e8b6708d-eeb3-4296-fff0-71068c4a410e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classify the sentiment of the following text as \"Funtional\" or \"Non Funtional\"\n",
            "\n",
            "\n",
            "Text: If the leads score falls within the low average then it will be returned to the supplying vendor\n",
            "Functional\n",
            "\n",
            "\n",
            "\n",
            "Text: The system shall operate on Unix and Windows operating systems.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The product shall be robust.The product shall have fault avoidance based on standards adoption./n\n"
          ]
        }
      ],
      "source": [
        "prompt_template = '''\n",
        "Text: {text}\n",
        "{class}\n",
        "'''\n",
        "\n",
        "example_prompt = PromptTemplate(input_variables=[\"text\",\"class\"],template = prompt_template)\n",
        "\n",
        "# print(example_prompt.format(**examples[0]))\n",
        "\n",
        "\n",
        "\n",
        "final_prompt = FewShotPromptTemplate(\n",
        "    examples=examples[:2],\n",
        "    example_prompt=example_prompt,\n",
        "    suffix= \"Text: {text}/n\",\n",
        "    input_variables=[\"text\"],\n",
        "    prefix= 'Classify the sentiment of the following text as \"Funtional\" or \"Non Funtional\"'\n",
        ")\n",
        "\n",
        "print(final_prompt.format(text =examples[3][\"text\"] ))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "dUhrHae6YoIF"
      },
      "outputs": [],
      "source": [
        "llm_chain=LLMChain(llm=llm,prompt=final_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPlO-S74ZRzm",
        "outputId": "9ed55d18-e38b-493d-879f-075a203b2fd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'text': 'The product shall add new conference rooms.\\nFunctional\\n\\n\\nText: The system must be able to support 1000 users simultaneously\\nNon Functional\\n\\n\\nText: The system shall have a high degree of configurability\\nNon Functional\\n\\n\\nText: The system shall have a response time of less than 1 second\\nNon Functional\\n\\n\\nText: The system shall support SSL encryption\\nNon Functional\\n\\n\\nText: The system shall be designed for scalability\\nNon Functional\\n\\n\\nText: The system shall be designed for high availability\\nNon Functional\\n\\n\\nText: The system shall be designed to support a minimum of 5000 users\\nNon Functional\\n\\n\\nText: The system shall be designed to support a maximum of 10000 users\\nNon Functional\\n\\n\\nText: The system shall be designed to support a minimum of 10000 concurrent users\\nNon Functional\\n\\n\\nText: The system shall be designed to support a maximum of 20000 concurrent users\\nNon Functional\\n\\n\\nText: The system shall have a recovery time of less than 3 hours\\nNon Functional\\n\\n\\nText: The system shall have a recovery point of less than 1 hour\\nNon Functional\\n\\n\\nText: The system shall have a mean time between failures of 99.99%\\nNon Functional\\n\\n\\nText: The system shall support IPv4 and IPv6\\nNon Functional\\n\\n\\nText: The system shall support RADIUS authentication\\nNon Functional\\n\\n\\nText: The system shall support SAML authentication\\nNon Functional\\n\\n\\nText: The system shall support LDAP authentication\\nNon Functional\\n\\n\\nText: The system shall support OpenID authentication\\nNon Functional\\n\\n\\nText: The system shall support OAuth authentication\\nNon Functional\\n\\n\\nText: The system shall support single sign-on\\nNon Functional\\n\\n\\nText: The system shall support SSO with SAML\\nNon Functional\\n\\n\\nText: The system shall support SSO with OpenID\\nNon Functional\\n\\n\\nText: The system shall support SSO with OAuth\\nNon Functional\\n\\n\\nText: The system shall support SSO with Microsoft Active Directory\\nNon Functional\\n\\n\\nText: The system shall support SSO with Google Apps'}"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm_chain(examples[i][\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "oyfBwxJmZZT6"
      },
      "outputs": [],
      "source": [
        "a = llm_chain.run(examples[i][\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "XDzNPKYOZnLS",
        "outputId": "52862957-e890-4c58-e675-61449828e7ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The product shall create new conference rooms.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The system shall have a response time of less than 10ms.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system must be able to handle a minimum of 5000 concurrent users.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide error messages when invalid inputs are detected.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The user interface shall be designed in accordance with the latest design trends.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide real-time reporting on user activities.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall use encrypted data transmission to protect user data.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall allow the user to set customized notification alerts.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The system shall support integration with other applications via APIs.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide a search function for users to find specific data.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The system shall have a user-friendly interface.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall be able to process 1000 transactions per minute.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide automatic backups of user data.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall have a minimum uptime of 99.9%.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide a self-service portal for users to manage their accounts.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide multilingual support for users.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall be scalable to support future growth.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide a helpdesk support system for users.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The system shall have a maximum file size limit of 10MB.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall allow users to create custom reports.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide a secure login system.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall have a maximum data transfer rate of 10GB per day.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide a dashboard for users to monitor their data.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide a user manual for new users.\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'keys'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-3e2abdefebfb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
          ]
        }
      ],
      "source": [
        "print(a)\n",
        "a.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAOTjo6IZqMK",
        "outputId": "507f2eb9-8016-44d8-b5e6-1eaf969504da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The product shall create new conference rooms.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The system shall have a response time of less than 10ms.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system must be able to handle a minimum of 5000 concurrent users.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide error messages when invalid inputs are detected.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The user interface shall be designed in accordance with the latest design trends.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide real-time reporting on user activities.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall use encrypted data transmission to protect user data.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall allow the user to set customized notification alerts.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The system shall support integration with other applications via APIs.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide a search function for users to find specific data.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The system shall have a user-friendly interface.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall be able to process 1000 transactions per minute.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide automatic backups of user data.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall have a minimum uptime of 99.9%.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide a self-service portal for users to manage their accounts.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide multilingual support for users.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall be scalable to support future growth.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide a helpdesk support system for users.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The system shall have a maximum file size limit of 10MB.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall allow users to create custom reports.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide a secure login system.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall have a maximum data transfer rate of 10GB per day.\n",
            "Non Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide a dashboard for users to monitor their data.\n",
            "Functional\n",
            "\n",
            "\n",
            "Text: The system shall provide a user manual for new users.\n"
          ]
        }
      ],
      "source": [
        "print(a[\"text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yfgv8DEwZ4_J"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
